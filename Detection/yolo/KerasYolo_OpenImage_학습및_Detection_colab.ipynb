{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python [conda env:tf113] *","language":"python","name":"conda-env-tf113-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"},"colab":{"name":"KerasYolo_OpenImage_학습및_Detection_colab.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"S-jUz1GdwbPT","colab_type":"text"},"source":["#### Open Image Dataset의 Object Detection 학습 및 Inference\n","* Open Image Dataset에서 Football 관련 Object, Fish관련 Object를 추출 후 학습 데이터 세트 생성. \n","* 이를 이용하여 Object Detection 수행. "]},{"cell_type":"markdown","metadata":{"id":"xgKlLEVHw74L","colab_type":"text"},"source":["### 본 실습 예제는 GPU를 활용하므로 상단 메뉴에서 런타임->런타임 유형 변경에서 GPU를 선택해 주십시요.\n","\n","### tensorflow, keras 설치 및 강의 실습코드/데이터 Download\n","\n","#### 공지\n","\n","현재(2020년 8월 11일) Colab에서 GPU 커널 적용시 tensorflow 1.13으로 downgrade가 되지 않습니다. 때문에 colab에서는 Segmentation 학습 시 tensorflow 1.15, keras 2.3 을 설치하겠습니다.\n","\n","Colab 버전colab에서 pip 명령어를 이용하여 tensorflow 1.15, keras 2.3를 소스코드 커널 기동시 마다 설치해야 합니다\n","\n","Colab의 tensorflow는 2020년 기준으로 2.2 이며, keras는 2.3입니다. 실습코드는 tensorflow 1.13과 1.15, keras 2.2와 2.3 기준으로 되어 있으므로 이를 downgrade해야 합니다.\n","\n","pip를 이용하여 tensorflow 1.15을 설치하면 자동으로 downgrade 됩니다.\n","\n","OpenCV는 Colab에서 이미 설치 되어 있으니 추가설치는 필요 없습니다.\n","\n","강의 실습코드와 데이터는 https://github.com/chulminkw/DLCV.git 에서 다운로드 할 수 있습니다. "]},{"cell_type":"code","metadata":{"id":"CQ2fYmI5xD69","colab_type":"code","colab":{}},"source":["# 현재 디렉토리는 /content이며 이 디렉토리를 기준으로 실습코드와 데이터를 다운로드 합니다. \n","!pwd\n","!rm -rf DLCV\n","!git clone https://github.com/chulminkw/DLCV.git\n","# DLCV 디렉토리가 Download되고 DLCV 밑에 Detection과 Segmentation 디렉토리가 있는 것을 확인\n","!ls -lia \n","!ls -lia DLCV\n","\n","#현재(2020년 8월 11일) Colab에서 GPU 커널 적용시 tensorflow 1.13으로 downgrade가 되지 않습니다. \n","#때문에 colab에서는 Segmentation 학습 시 tensorflow 1.15, keras 2.3 을 설치하겠습니다.\n","# tensorflow 1.15을 설치합니다. 자동으로 tensorflow 2.2가 1.15로 downgrade 됩니다. \n","!pip install tensorflow-gpu==1.15.2 \n","# keras 2.3를 설치합니다. \n","!pip install keras==2.3.0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2RQ_TrUsRfR_","colab_type":"text"},"source":["### 중요. 반드시 아래 import tensorflow, import keras 수행 전 이 셀을 먼저 수행해야 합니다. \n","#### Keras-yolo3 는 Custom data 를 train시 오류가 발생하는등 tensorflow 1.15 와 완벽하게 호환하지 않습니다. \n","#### 때문에 아래와 같이 DLCV github에서 수정된 __init__.py 를 다운로드 받아서 keras의 backend의 __init__.py 를 수정해야 합니다.\n","#### __init__.py는 반드시 import tensorflow, import keras 이전에 수행되어야 합니다. 만일 tensorflow, keras 설치한 뒤 아래의 import tensorflow, import keras를 먼저 수행하였으면 메뉴-> 런타임 -> 런타임 다시 시작을 누르신 뒤 __init__.py를 수정합니다. "]},{"cell_type":"code","metadata":{"id":"BjuXqprWswW9","colab_type":"code","colab":{}},"source":["import os\n","\n","# keras backend 디렉토리 이동. \n","os.chdir('/usr/local/lib/python3.6/dist-packages/keras/backend')\n","\n","!rm -rf __init__.py\n","!rm -rf __pycache__\n","# 기존 __init__.py 삭제하고 새로운 __init__.py를 download \n","!wget https://raw.githubusercontent.com/chulminkw/DLCV/master/colab_tf115_modify_files/__init__.py"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bP9IYjsKxpY9","colab_type":"code","colab":{}},"source":["# tensorflow는 1.15, keras는 2.3 버전 확인\n","# GPU가 세팅되어 있지 않으면 상단 메뉴에서 런타임->런타임 유형 변경에서 GPU를 선택한 후 런타임 다시 시작을 선택하고 처음 부터인 tensorflow, keras 설치 부터 다시 시작. \n","import tensorflow as tf\n","import keras\n","\n","print(tf.__version__)\n","print(keras.__version__)\n","\n","# gpu가 세팅드어 있는지 확인. \n","tf.test.gpu_device_name()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m1QyM1d4S6EN","colab_type":"text"},"source":["### 코랩 버전은 아래를 이용하여 keras-yolo3 패키지를 download하여 /content/DLCV/Detection/yolo 밑에 설치 "]},{"cell_type":"code","metadata":{"id":"7xws2a8XS7x_","colab_type":"code","colab":{}},"source":["%cd /content/DLCV/Detection/yolo\n","!git clone https://github.com/qqwweee/keras-yolo3.git\n","!ls -lia /content/DLCV/Detection/yolo/keras-yolo3\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gBs-eKhRTcpu","colab_type":"text"},"source":["### 코랩 버전 pretrained 모델 재생성 및 font 디렉토리 교체  \n","* 코랩 버전은 다시 model_data 밑에 coco dataset로 pretrained 된 yolov3.weights 파일을 yolo.h5 파일로 변경해 줘야 합니다. \n","* keras-yolo3의 font 디렉토리도 재 교체 합니다. "]},{"cell_type":"code","metadata":{"id":"byY8HOzcTZej","colab_type":"code","colab":{}},"source":["# 코랩 버전은 아래를 이용하여 yolov3.weights 파일을 download 받고, convert.py 를 수행하여 model_data 밑에 yolo.h5 파일 생성 수행. \n","%cd /content/DLCV/Detection/yolo/keras-yolo3 \n","# yolo 공식 사이트에서 download시 download 속도가 약 25분 정도 소요됨. 강의 github에서 다운로드 요망. \n","#!wget  https://pjreddie.com/media/files/yolov3.weights\n","# 강의 실습 github에서 다운로드\n","!wget https://github.com/chulminkw/DLCV/releases/download/1.0/yolov3.weights\n","\n","# yolov3.weights를 keras-yolo3에서 사용할 수 있도록 yolo.h5 로 변환\n","!python convert.py yolov3.cfg yolov3.weights model_data/yolo.h5\n","# model_data 밑에 yolo.h5 파일이 생성되었는지 확인. \n","!ls /content/DLCV/Detection/yolo/keras-yolo3/model_data\n","# yolo.detect_image() 메소드는 PIL package를 이용하여 image 작업 수행. keras-yolo3/font 디렉토리를 상위 디렉토리로 복사 해야함.  \n","%cd /content/DLCV/Detection/yolo\n","!cp -rf keras-yolo3/font ./font"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_fBDpmk4yAsJ","colab_type":"text"},"source":["#### 코랩 버전은 이미 OID Toolkit을 통해 만들어진 데이터 세트를 다운로드 합니다. \n","* 코랩 버전은 OID Toolkit을 사용하는 동영상 강의를 참조하지 않으셔도 됩니다. \n","* 이미 만들어진 ballnfish.tar 파일을 다운로드 한 뒤 이를 이용하여 학습 합니다. "]},{"cell_type":"code","metadata":{"id":"mgAZXivoVf8Z","colab_type":"code","colab":{}},"source":["# ballnfish.tar 파일을 강의의 github에서 download 한 뒤 압축을 풀면\n","# /content/DLCV/data/ballnfish 디렉토리로 annotations, images 디렉토리와 관련 파일들이 생성 됩니다. \n","%cd /content/DLCV/data\n","!wget https://github.com/chulminkw/DLCV/releases/download/1.0/ballnfish.tar\n","!tar -xvf ballnfish.tar > /dev/null 2>&1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ltszcSahwbPj","colab_type":"code","colab":{}},"source":["# annotation과 image 디렉토리 설정. annotation디렉토리에 있는 파일 확인. \n","import os\n","from pathlib import Path\n","\n","#HOME_DIR = str(Path.home())\n","# 코랩 버전은 HOME_DIR을 /content 로 설정합니다.\n","HOME_DIR = '/content'\n","\n","ANNO_DIR = os.path.join(HOME_DIR, 'DLCV/data/ballnfish/annotations')\n","IMAGE_DIR = os.path.join(HOME_DIR, 'DLCV/data/ballnfish/images')\n","print(ANNO_DIR)\n","\n","files = os.listdir(ANNO_DIR)\n","print('파일 개수는:',len(files))\n","print(files)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tytfc03DwbPv","colab_type":"code","colab":{}},"source":["# 아래는 위에서 출력된 적당한 xml 파일로 변경되어야 합니다. \n","!cat /content/DLCV/data/ballnfish/annotations/13825baad5531265.xml"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"45EwAa_XYkLI","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EzEC9t1TwbP3","colab_type":"code","colab":{}},"source":["import glob\n","import xml.etree.ElementTree as ET\n","\n","classes_map = {'Football':0, 'Football_helmet':1, 'Fish':2, 'Shark':3, 'Shellfish':4 }\n","\n","def xml_to_csv(path, output_filename):\n","    xml_list = []\n","    # xml 확장자를 가진 모든 파일의 절대 경로로 xml_file할당. \n","    with open(output_filename, \"w\") as train_csv_file:\n","        for xml_file in glob.glob(path + '/*.xml'):\n","            # xml 파일을 parsing하여 XML Element형태의 Element Tree를 생성하여 object 정보를 추출. \n","            tree = ET.parse(xml_file)\n","            root = tree.getroot()\n","            print('xml file:', xml_file)\n","            # 파일내에 있는 모든 object Element를 찾음. \n","            full_image_name = os.path.join(IMAGE_DIR, root.find('filename').text)\n","            value_str_list = ' '\n","            for obj in root.findall('object'):\n","                xmlbox = obj.find('bndbox')\n","                class_name = obj.find('name').text\n","                x1 = int(xmlbox.find('xmin').text)\n","                y1 = int(xmlbox.find('ymin').text)\n","                x2 = int(xmlbox.find('xmax').text)\n","                y2 = int(xmlbox.find('ymax').text)\n","                # \n","                class_id = classes_map[class_name]\n","                value_str = ('{0},{1},{2},{3},{4}').format(x1, y1, x2, y2, class_id)\n","                # object별 정보를 tuple형태로 object_list에 저장. \n","                value_str_list = value_str_list+value_str+' '\n","        \n","            train_csv_file.write(full_image_name+' '+ value_str_list+'\\n')\n","        # xml file 찾는 for loop 종료 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3_sIpmXUwbP-","colab_type":"code","colab":{}},"source":["xml_to_csv(ANNO_DIR, os.path.join(ANNO_DIR,'ballnfish_anno.csv'))\n","print(os.path.join(ANNO_DIR,'ballnfish_anno.csv'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hbnqqUQ5wbQF","colab_type":"code","colab":{}},"source":["!cat /content/DLCV/data/ballnfish/annotations/ballnfish_anno.csv"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yT94skQ6wbQN","colab_type":"code","colab":{}},"source":["import cv2\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","default_dir = '/content'\n","# 9c27811a78b74a48.jpg 는 images 디렉토리에 있는 임의 파일로 바뀌어야 합니다. \n","plt.imshow(cv2.cvtColor(cv2.imread(os.path.join(default_dir, 'DLCV/data/ballnfish/images/9c27811a78b74a48.jpg')), cv2.COLOR_BGR2RGB))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"49UnJbJuwbQS","colab_type":"code","colab":{}},"source":["import numpy as np\n","import keras.backend as K\n","from keras.layers import Input, Lambda\n","from keras.models import Model\n","from keras.optimizers import Adam\n","from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MHKYA4gMwbQW","colab_type":"code","colab":{}},"source":["import sys, os\n","\n","import os\n","\n","# 코랩 버전은 아래와 같이 절대 경로를 지정하여 Local Package 지정. \n","default_dir = '/content/DLCV'\n","default_yolo_dir = os.path.join(default_dir, 'Detection/yolo')\n","\n","LOCAL_PACKAGE_DIR = os.path.abspath(os.path.join(default_yolo_dir,'keras-yolo3'))\n","print(LOCAL_PACKAGE_DIR)\n","sys.path.append(LOCAL_PACKAGE_DIR)\n","\n","from yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss\n","from yolo3.utils import get_random_data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UbZVkTbaZfCQ","colab_type":"text"},"source":["#### colab 버전은 아래 명령어로 ballnfish_classes.txt 를 수정"]},{"cell_type":"code","metadata":{"id":"gTsQFZxc5r7U","colab_type":"code","colab":{}},"source":["# colab 버전은 아래 명령어로 ballnfish_classes.txt 를 수정합니다. \n","BASE_DIR = os.path.join(HOME_DIR, 'DLCV/Detection/yolo/keras-yolo3')\n","classes_path = os.path.join(BASE_DIR, 'model_data/ballnfish_classes.txt')\n","with open(classes_path, \"w\") as f:\n","    f.write(\"Football\\n\")\n","    f.write(\"Football_Helmet\\n\")\n","    f.write(\"Fish\\n\")\n","    f.write(\"Shark\\n\")\n","    f.write(\"Shell_Fish\\n\")\n","\n","# colab 버전은 raccoon_class.txt에 제대로 기재되었나 확인. \n","!cat /content/DLCV/Detection/yolo/keras-yolo3/model_data/ballnfish_classes.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0RGGXw-kwbQd","colab_type":"code","colab":{}},"source":["from train import get_classes, get_anchors\n","from train import create_model, data_generator, data_generator_wrapper\n","\n","BASE_DIR = os.path.join(HOME_DIR, 'DLCV/Detection/yolo/keras-yolo3')\n","\n","## 학습을 위한 기반 환경 설정. annotation 파일 위치, epochs시 저장된 모델 파일, Object클래스 파일, anchor 파일.\n","annotation_path = os.path.join(ANNO_DIR, 'ballnfish_anno.csv')\n","log_dir = os.path.join(BASE_DIR, 'snapshots/ballnfish/')\n","classes_path = os.path.join(BASE_DIR, 'model_data/ballnfish_classes.txt')\n","anchors_path = os.path.join(BASE_DIR,'model_data/yolo_anchors.txt')\n","\n","class_names = get_classes(classes_path)\n","num_classes = len(class_names)\n","anchors = get_anchors(anchors_path)\n","print(class_names, num_classes)\n","print(anchors)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vZfsCS2OwbQj","colab_type":"text"},"source":["#### yolo 모델 학습을 위한 전반적인 파라미터를 config 클래스로 설정하고 필요시 이를 수정하여 학습. "]},{"cell_type":"code","metadata":{"id":"A2xsA4ZBwbQk","colab_type":"code","colab":{}},"source":["# csv annotation 파일을 읽어서 lines 리스트로 만듬. \n","with open(annotation_path) as f:\n","    lines = f.readlines()\n","\n","class config:\n","    #tiny yolo로 모델로 초기 weight 학습 원할 시 아래를 tiny-yolo.h5로 수정. \n","    initial_weights_path=os.path.join(BASE_DIR, 'model_data/yolo.h5' )\n","    # input_shape는 고정. \n","    input_shape=(416, 416)\n","    # epochs는 freeze, unfreeze 2 step에 따라 설정. \n","    first_epochs=50\n","    first_initial_epochs=0\n","    second_epochs=100\n","    second_initial_epochs=50\n","    # 학습시 batch size, train,valid건수, epoch steps 횟수  \n","    batch_size = 4\n","    val_split = 0.1   \n","    num_val = int(len(lines)*val_split)\n","    num_train = len(lines) - num_val\n","    train_epoch_steps = num_train//batch_size \n","    val_epoch_steps =  num_val//batch_size\n","    \n","    anchors = get_anchors(anchors_path)\n","    class_names = get_classes(classes_path)\n","    num_classes = len(class_names)\n","    # epoch시 저장된 weight 파일 디렉토리 \n","    log_dir = os.path.join(BASE_DIR, 'snapshots/ballnfish/')\n","    \n","print('Class name:', config.class_names,'\\nNum classes:', config.num_classes)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aBX0iMTAwbQs","colab_type":"text"},"source":["#### csv 파일을 입력 받아서 train 데이터와 valid 데이터 처리를 위한 data_generator_wrapper객체를 각각 생성.\n","* train용, valid 용 data_generator_wrapper는 Yolo 모델의 fit_generator()학습시 인자로 입력됨. "]},{"cell_type":"code","metadata":{"id":"fhCB6mEvwbQt","colab_type":"code","colab":{}},"source":["def create_generator(lines):\n","    \n","    train_data_generator = data_generator_wrapper(lines[:config.num_train], config.batch_size, \n","                                                  config.input_shape, config.anchors, config.num_classes)\n","    \n","    valid_data_generator = data_generator_wrapper(lines[config.num_train:], config.batch_size, \n","                                                  config.input_shape, config.anchors, config.num_classes)\n","    \n","    return train_data_generator, valid_data_generator"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IrNhCvIWwbQz","colab_type":"text"},"source":["#### YOLO 모델 또는 tiny yolo 모델 반환. 초기 weight값은 pretrained된 yolo weight값으로 할당. "]},{"cell_type":"code","metadata":{"id":"zPGFrumswbQ1","colab_type":"code","colab":{}},"source":["# anchor 개수에 따라 tiny yolo 모델 또는 yolo 모델 반환. \n","def create_yolo_model():\n","    is_tiny_version = len(config.anchors)==6 \n","    if is_tiny_version:\n","        model = create_tiny_model(config.input_shape, config.anchors, config.num_classes, \n","            freeze_body=2, weights_path=config.initial_weights_path)\n","    else:\n","        model = create_model(config.input_shape, config.anchors, config.num_classes, \n","            freeze_body=2, weights_path=config.initial_weights_path)\n","        \n","    return model "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tkfuszO5wbQ5","colab_type":"text"},"source":["#### callback 객체들을 생성. "]},{"cell_type":"code","metadata":{"id":"_1mceN4twbQ6","colab_type":"code","colab":{}},"source":["# Tensorboard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping callback 반환\n","def create_callbacks():\n","    logging = TensorBoard(log_dir=config.log_dir)\n","    checkpoint = ModelCheckpoint(config.log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n","        monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n","    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n","    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n","    \n","    #개별 callback들을 한꺼번에 list로 묶어서 반환\n","    return [logging, checkpoint, reduce_lr, early_stopping]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0CmFkqkiwbRA","colab_type":"text"},"source":["#### 학습 수행"]},{"cell_type":"code","metadata":{"id":"G54xY46MwbRB","colab_type":"code","colab":{}},"source":["   \n","# create_generator(), create_model(), create_callbacks() 수행. \n","train_data_generator, valid_data_generator = create_generator(lines)\n","ballnfish_model = create_yolo_model()\n","callbacks_list = create_callbacks()\n","\n","# 최초 모델은 주요 layer가 freeze되어 있음. 안정적인 loss를 확보하기 위해 주요 layer를 freeze한 상태로 먼저 학습. \n","print('First train 시작' )\n","ballnfish_model.compile(optimizer=Adam(lr=1e-3), loss={'yolo_loss': lambda y_true, y_pred: y_pred})\n","\n","ballnfish_model.fit_generator(train_data_generator, steps_per_epoch=config.train_epoch_steps,\n","        validation_data=valid_data_generator, validation_steps=config.val_epoch_steps,\n","        epochs=config.first_epochs, initial_epoch=config.first_initial_epochs, \n","        callbacks=callbacks_list)\n","\n","# 1단계 학습 완료 모델 저장. \n","ballnfish_model.save_weights(log_dir + 'trained_weights_stage_1.h5')\n","\n","# 모든 layer를 trainable=True로 설정하고 학습 수행. \n","for i in range(len(ballnfish_model.layers)):\n","    ballnfish_model.layers[i].trainable = True\n","    \n","print('Second train 시작' )\n","ballnfish_model.compile(optimizer=Adam(lr=1e-4), loss={'yolo_loss': lambda y_true, y_pred: y_pred}) \n","ballnfish_model.fit_generator(train_data_generator, steps_per_epoch=config.train_epoch_steps,\n","    validation_data=valid_data_generator, validation_steps=config.val_epoch_steps,\n","    epochs=config.second_epochs, initial_epoch=config.second_initial_epochs,\n","    callbacks=callbacks_list)\n","\n","# 최종 학습 완료 모델 저장. \n","ballnfish_model.save_weights(log_dir + 'trained_weights_final.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rz_pdp5LwbRG","colab_type":"text"},"source":["#### 최종 학습된 모델을 로딩하여 Object Detection 수행. "]},{"cell_type":"code","metadata":{"id":"YiYNtp7VwbRH","colab_type":"code","colab":{}},"source":["from yolo import YOLO\n","#keras-yolo에서 image처리를 주요 PIL로 수행. \n","from PIL import Image\n","\n","# 코랩 버전은 아래와 같이 절대 경로를 지정하여 Local Package 지정. \n","default_dir = '/content/DLCV'\n","default_yolo_dir = os.path.join(default_dir, 'Detection/yolo')\n","\n","LOCAL_PACKAGE_DIR = os.path.abspath(os.path.join(default_yolo_dir,'keras-yolo3'))\n","sys.path.append(LOCAL_PACKAGE_DIR)\n","\n","ballnfish_yolo = YOLO(model_path='/content/DLCV/Detection/yolo/keras-yolo3/snapshots/ballnfish/trained_weights_final.h5',\n","            anchors_path='/content/DLCV/Detection/yolo/keras-yolo3/model_data/yolo_anchors.txt',\n","            classes_path='/content/DLCV/Detection/yolo/keras-yolo3/model_data/ballnfish_classes.txt')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FEq_2Q6HwbRL","colab_type":"text"},"source":["#### 이미지 Object Detection"]},{"cell_type":"code","metadata":{"id":"gHabBPZfEfve","colab_type":"code","colab":{}},"source":["%cd /content/DLCV/data/ballnfish\n","!ls annotations"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0B8rYzO5wbRM","colab_type":"code","colab":{}},"source":["# 아래 football_list는 적절한 jpg 파일명으로 변경되어야 합니다. \n","football_list = ['f1b492a9bce3ac9a.jpg', '1e6ff631bb0c198b.jpg', '97ac013310bda756.jpg',\n","                'e5b1646c395aecfd.jpg', '53ef241dad498f6c.jpg', '02ccbf5ddaaecedb.jpg' ]\n","for image_name in football_list:\n","    img = Image.open(os.path.join(IMAGE_DIR, image_name))\n","    detected_img = ballnfish_yolo.detect_image(img)\n","    plt.figure(figsize=(8, 8))\n","    plt.imshow(detected_img)\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bgZA4HeGwbRQ","colab_type":"code","colab":{}},"source":["# 아래 helmet_list는 적절한 jpg 파일명으로 변경되어야 합니다. \n","helmet_list = ['1fed5c930211c6e0.jpg', '011a59a160d7a091.jpg', 'd39b46aa4bc0c165.jpg', '7e9eb7eba80e34e7.jpg', '9c27811a78b74a48.jpg']\n","for image_name in helmet_list:\n","    img = Image.open(os.path.join(IMAGE_DIR, image_name))\n","    detected_img = ballnfish_yolo.detect_image(img)\n","    plt.figure(figsize=(8, 8))\n","    plt.imshow(detected_img)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PGy-AQu6wbRV","colab_type":"code","colab":{}},"source":["# 아래 fish_list는 적절한 jpg 파일명으로 변경되어야 합니다.\n","fish_list = ['25e42c55bfcbaa88.jpg', 'a571e4cdcfbcb79e.jpg', '872c435491f2b4d3.jpg', \n","             'bebac23c45451d93.jpg', 'eba7caf07a26829b.jpg', 'dc607a2989bdc9dc.jpg' ]\n","for image_name in fish_list:\n","    img = Image.open(os.path.join(IMAGE_DIR, image_name))\n","    detected_img = ballnfish_yolo.detect_image(img)\n","    plt.figure(figsize=(8, 8))\n","    plt.imshow(detected_img)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_gsZ--eRwbRb","colab_type":"code","colab":{}},"source":["#아래 shark_list는 적절한 jpg 파일명으로 변경되어야 합니다.\n","shark_list = ['d92290f6c04dd83b.jpg', '3a37a09ec201cdeb.jpg', '32717894b5ce0052.jpg', 'a848df5dbed78a0f.jpg', '3283eafe11a847c3.jpg']\n","for image_name in shark_list:\n","    img = Image.open(os.path.join(IMAGE_DIR, image_name))\n","    detected_img = ballnfish_yolo.detect_image(img)\n","    plt.figure(figsize=(8, 8))\n","    plt.imshow(detected_img)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OQLbaY5rwbRf","colab_type":"code","colab":{}},"source":["#아래 shell_list는 적절한 jpg 파일명으로 변경되어야 합니다.\n","shell_list=['5cc89bc28084e8e8.jpg',  '055e756883766e1f.jpg', '089354fc39f5d82d.jpg', '80eddfdcb3384458.jpg']\n","for image_name in shell_list:\n","    img = Image.open(os.path.join(IMAGE_DIR, image_name))\n","    detected_img = ballnfish_yolo.detect_image(img)\n","    plt.figure(figsize=(8, 8))\n","    plt.imshow(detected_img)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8oL6dILwFLIF","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ULvNtKurFLay","colab_type":"text"},"source":["#### keras-yolo 패키지의 font 디렉토리 이동 "]},{"cell_type":"code","metadata":{"id":"RYyYHQc7FDku","colab_type":"code","colab":{}},"source":["%cd /content/DLCV/Detection/yolo\n","!cp -rf keras-yolo3/font ./font"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l2wPC9QmwbRm","colab_type":"text"},"source":["#### 영상 Object Detection "]},{"cell_type":"code","metadata":{"id":"UeA9Cl92wbRn","colab_type":"code","colab":{}},"source":["import cv2\n","import time\n","\n","def detect_video_yolo(model, input_path, output_path=\"\"):\n","    \n","    start = time.time()\n","    cap = cv2.VideoCapture(input_path)\n","    \n","    #codec = cv2.VideoWriter_fourcc(*'DIVX')\n","    codec = cv2.VideoWriter_fourcc(*'XVID')\n","    vid_fps = cap.get(cv2.CAP_PROP_FPS)\n","    vid_size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n","    vid_writer = cv2.VideoWriter(output_path, codec, vid_fps, vid_size)\n","    \n","    frame_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    print('총 Frame 갯수:', frame_cnt, '원본 영상 FPS:',vid_fps, '원본 Frame 크기:', vid_size)\n","    index = 0\n","    while True:\n","        hasFrame, image_frame = cap.read()\n","        if not hasFrame:\n","            print('프레임이 없거나 종료 되었습니다.')\n","            break\n","        start = time.time()\n","        # PIL Package를 내부에서 사용하므로 cv2에서 읽은 image_frame array를 다시 PIL의 Image형태로 변환해야 함.  \n","        image = Image.fromarray(image_frame)\n","        # 아래는 인자로 입력된 yolo객체의 detect_image()로 변환한다.\n","        detected_image = model.detect_image(image)\n","        # cv2의 video writer로 출력하기 위해 다시 PIL의 Image형태를 array형태로 변환 \n","        result = np.asarray(detected_image)\n","        index +=1\n","        print('#### frame:{0} 이미지 처리시간:{1}'.format(index, round(time.time()-start,3)))\n","        \n","        vid_writer.write(result)\n","    \n","    vid_writer.release()\n","    cap.release()\n","    print('### Video Detect 총 수행시간:', round(time.time()-start, 5))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zl16lIcdwbRq","colab_type":"code","colab":{}},"source":["detect_video_yolo(ballnfish_yolo, '/content/DLCV/data/video/NFL01.mp4', '/content/DLCV/data/output/NFL_yolo_01.avi')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z5HpgKONbFNT","colab_type":"code","colab":{}},"source":["## colab 버전은 Object Detection 적용된 영상 파일을 google drive에서 download 해야 합니다. 이를 위해 google drive를 colab에 mount 수행. \n","import os, sys \n","from google.colab import drive \n","\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dls1PgDdbQXV","colab_type":"code","colab":{}},"source":["## colab 버전은 Object Detection 적용된 영상 파일을 google drive에서 download 해야 합니다. \n","## My Drive 디렉토리 이름에 공란이 있으므로 ' '로 묶습니다. \n","!cp /content/DLCV/data/output/NFL_yolo_01.avi '/content/gdrive/My Drive/NFL_yolo_01.avi'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fCsf8YxJwbRv","colab_type":"code","colab":{}},"source":["detect_video_yolo(ballnfish_yolo, '/content/DLCV/data/video/FishnShark01.mp4', '/content/DLCV/data/output/FishnShark_yolo_01.avi')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7OXPaNarwbRz","colab_type":"code","colab":{}},"source":["## colab 버전은 Object Detection 적용된 영상 파일을 google drive에서 download 해야 합니다. \n","## My Drive 디렉토리 이름에 공란이 있으므로 ' '로 묶습니다. \n","!cp /content/DLCV/data/output/FishnShark_yolo_01.avi '/content/gdrive/My Drive/FishnShark_yolo_01.avi'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r9i8xMVqwbR3","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKxgIatXwbR6","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ZUh_V06wbR-","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}