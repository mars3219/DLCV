{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python [conda env:tf113] *","language":"python","name":"conda-env-tf113-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"},"colab":{"name":"KerasYolo_이미지와_영상_Detection_colab.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"AcpfOESmtIE5","colab_type":"text"},"source":["### keras-yolo3 패키지를 이용하여 Yolo와 tiny Yolo 기반으로 이미지와 영상 Object Detection 수행\n","* 다크넷에서 Pretrained된 yolo/tiny-yolo weights 모델을 다운로드\n","* 다운로드한 다크넷 weight 파일을 기반으로 keras-yolo3에서 사용할 수 있는 weight 파일로 변환 후 이를 이용하여 Object Detection 수행"]},{"cell_type":"markdown","metadata":{"id":"vQJ85O4Mx9x7","colab_type":"text"},"source":["### 본 실습 예제는 GPU를 활용하므로 상단 메뉴에서 런타임->런타임 유형 변경에서 GPU를 선택해 주십시요."]},{"cell_type":"markdown","metadata":{"id":"UZ8Y5aB2x_3z","colab_type":"text"},"source":["### tensorflow, keras 설치 및 강의 실습코드/데이터 Download\n","#### 공지\n","\n","현재(2020년 8월 11일) Colab에서 GPU 커널 적용시 tensorflow 1.13으로 downgrade가 되지 않습니다. 때문에 colab에서는 Segmentation 학습 시 tensorflow 1.15, keras 2.3 을 설치하겠습니다.\n","\n","Colab 버전colab에서 pip 명령어를 이용하여 tensorflow 1.15, keras 2.3를 소스코드 커널 기동시 마다 설치해야 합니다\n","\n","Colab의 tensorflow는 2020년 기준으로 2.2 이며, keras는 2.3입니다. 실습코드는 tensorflow 1.13과 1.15, keras 2.2와 2.3 기준으로 되어 있으므로 이를 downgrade해야 합니다.\n","\n","pip를 이용하여 tensorflow 1.15을 설치하면 자동으로 downgrade 됩니다.\n","\n","OpenCV는 Colab에서 이미 설치 되어 있으니 추가설치는 필요 없습니다.\n","\n","강의 실습코드와 데이터는 https://github.com/chulminkw/DLCV.git 에서 다운로드 할 수 있습니다. "]},{"cell_type":"code","metadata":{"id":"UcJ2oJ6zyMF9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":469},"executionInfo":{"status":"ok","timestamp":1597658519049,"user_tz":-540,"elapsed":28966,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"00f2bfd1-8d7f-444e-f930-53570ac11eea"},"source":["# 현재 디렉토리는 /content이며 이 디렉토리를 기준으로 실습코드와 데이터를 다운로드 합니다. \n","!pwd\n","!rm -rf DLCV\n","!git clone https://github.com/chulminkw/DLCV.git\n","# DLCV 디렉토리가 Download되고 DLCV 밑에 Detection과 Segmentation 디렉토리가 있는 것을 확인\n","!ls -lia \n","!ls -lia DLCV"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content\n","Cloning into 'DLCV'...\n","remote: Enumerating objects: 26, done.\u001b[K\n","remote: Counting objects: 100% (26/26), done.\u001b[K\n","remote: Compressing objects: 100% (22/22), done.\u001b[K\n","remote: Total 185 (delta 10), reused 0 (delta 0), pack-reused 159\u001b[K\n","Receiving objects: 100% (185/185), 134.41 MiB | 13.41 MiB/s, done.\n","Resolving deltas: 100% (67/67), done.\n","total 20\n","3932195 drwxr-xr-x 1 root root 4096 Aug 17 10:01 .\n","3946108 drwxr-xr-x 1 root root 4096 Aug 17 09:48 ..\n","3932196 drwxr-xr-x 1 root root 4096 Aug 10 21:25 .config\n","3946196 drwxr-xr-x 7 root root 4096 Aug 17 10:01 DLCV\n","3407899 drwxr-xr-x 1 root root 4096 Jul 30 16:30 sample_data\n","total 6456\n","3946196 drwxr-xr-x 7 root root    4096 Aug 17 10:01 .\n","3932195 drwxr-xr-x 1 root root    4096 Aug 17 10:01 ..\n","3946273 drwxr-xr-x 2 root root    4096 Aug 17 10:01 colab_tf115_modify_files\n","3946275 drwxr-xr-x 6 root root    4096 Aug 17 10:01 data\n","3946239 drwxr-xr-x 8 root root    4096 Aug 17 10:01 Detection\n","3946224 -rw-r--r-- 1 root root 6577714 Aug 17 10:01 DLCV_Colab_SrcCode_new.zip\n","3946197 drwxr-xr-x 8 root root    4096 Aug 17 10:01 .git\n","3946265 -rw-r--r-- 1 root root     142 Aug 17 10:01 README.md\n","3946266 drwxr-xr-x 3 root root    4096 Aug 17 10:01 Segmentation\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iZpM3sjryUah","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597658604426,"user_tz":-540,"elapsed":114310,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"3b841de2-3122-45e3-edb5-9d9ca735241d"},"source":["\n","#현재(2020년 8월 11일) Colab에서 GPU 커널 적용시 tensorflow 1.13으로 downgrade가 되지 않습니다. \n","#때문에 colab에서는 Segmentation 학습 시 tensorflow 1.15, keras 2.3 을 설치하겠습니다.\n","# tensorflow 1.15을 설치합니다. 자동으로 tensorflow 2.2가 1.15로 downgrade 됩니다. \n","!pip install tensorflow-gpu==1.15.2 \n","# keras 2.3를 설치합니다. \n","!pip install keras==2.3.0"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting tensorflow-gpu==1.15.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/ca/58e40e5077fa2a92004f398d705a288e958434f123938f4ce75ffe25b64b/tensorflow_gpu-1.15.2-cp36-cp36m-manylinux2010_x86_64.whl (411.0MB)\n","\u001b[K     |████████████████████████████████| 411.0MB 43kB/s \n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.1.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.34.2)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.8.1)\n","Collecting keras-applications>=1.0.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 5.9MB/s \n","\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.18.5)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.9.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (3.3.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.15.0)\n","Collecting tensorboard<1.16.0,>=1.15.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 42.1MB/s \n","\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.12.1)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.1.2)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (3.12.4)\n","Collecting gast==0.2.2\n","  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n","Collecting tensorflow-estimator==1.15.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n","\u001b[K     |████████████████████████████████| 512kB 39.8MB/s \n","\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.31.0)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.2.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.2) (2.10.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.2.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (1.0.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (49.2.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (1.7.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.1.0)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=72f4e4b7cb68aae47f11c5e7c531b722137784d2f759b32d83e87c71809d2fdd\n","  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n","Successfully built gast\n","\u001b[31mERROR: tensorflow 2.3.0 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.3.0 has requirement tensorboard<3,>=2.3.0, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.3.0 has requirement tensorflow-estimator<2.4.0,>=2.3.0, but you'll have tensorflow-estimator 1.15.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","Installing collected packages: keras-applications, tensorboard, gast, tensorflow-estimator, tensorflow-gpu\n","  Found existing installation: tensorboard 2.3.0\n","    Uninstalling tensorboard-2.3.0:\n","      Successfully uninstalled tensorboard-2.3.0\n","  Found existing installation: gast 0.3.3\n","    Uninstalling gast-0.3.3:\n","      Successfully uninstalled gast-0.3.3\n","  Found existing installation: tensorflow-estimator 2.3.0\n","    Uninstalling tensorflow-estimator-2.3.0:\n","      Successfully uninstalled tensorflow-estimator-2.3.0\n","Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.2\n","Collecting keras==2.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/18/2e1ef121e5560ac24c7ac9e363aa5fa7006c40563c989e7211aba95b793a/Keras-2.3.0-py2.py3-none-any.whl (377kB)\n","\u001b[K     |████████████████████████████████| 378kB 2.8MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (3.13)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (2.10.0)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.18.5)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.4.1)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.15.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.1.2)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.0.8)\n","Installing collected packages: keras\n","  Found existing installation: Keras 2.4.3\n","    Uninstalling Keras-2.4.3:\n","      Successfully uninstalled Keras-2.4.3\n","Successfully installed keras-2.3.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NFFGPYOkykok","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":95},"executionInfo":{"status":"ok","timestamp":1597658607732,"user_tz":-540,"elapsed":117604,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"be367470-2a5d-407a-ba6f-8a412c188724"},"source":["# tensorflow는 1.15, keras는 2.3 버전 확인\n","# GPU가 세팅되어 있지 않으면 상단 메뉴에서 런타임->런타임 유형 변경에서 GPU를 선택한 후 런타임 다시 시작을 선택하고 처음 부터인 tensorflow, keras 설치 부터 다시 시작. \n","import tensorflow as tf\n","import keras\n","\n","print(tf.__version__)\n","print(keras.__version__)\n","\n","# gpu가 세팅드어 있는지 확인. \n","tf.test.gpu_device_name()"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["1.15.2\n","2.3.0\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"FJV8R-0mtIE8","colab_type":"code","colab":{}},"source":["import os\n","import sys\n","import random\n","import math\n","import time\n","import numpy as np\n","import tensorflow as tf\n","import matplotlib\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HZVnwkL1zR_I","colab_type":"text"},"source":["### 코랩 버전은 아래를 이용하여 keras-yolo3 패키지를 download하여 /content/DLCV/Detection/yolo 밑에 설치 "]},{"cell_type":"code","metadata":{"id":"xpyJO4NwzBdP","colab_type":"code","colab":{}},"source":["%cd /content/DLCV/Detection/yolo\n","!git clone https://github.com/qqwweee/keras-yolo3.git\n","!ls -lia /content/DLCV/Detection/yolo/keras-yolo3"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-8-0BGmjtIFG","colab_type":"text"},"source":["#### Local Directory 상에서 yolo package를 import 함. \n","* keras-yolo3는 setup을 제공하지 않으므로 local directory상에서 바로 package를 import함. \n","* 이를 위해 keras-yolo3를 system path에 추가  \n","* keras-yolo3 디렉토리에 있는 yolo.py에서 YOLO class를 import하여 사용. "]},{"cell_type":"code","metadata":{"id":"Y5MQrrj6tIFM","colab_type":"code","colab":{}},"source":["# 코랩 버전은 아래와 같이 절대 경로를 지정하여 Local Package 지정. \n","default_dir = '/content/DLCV'\n","default_yolo_dir = os.path.join(default_dir, 'Detection/yolo')\n","\n","LOCAL_PACKAGE_DIR = os.path.abspath(os.path.join(default_yolo_dir,'keras-yolo3'))\n","print(LOCAL_PACKAGE_DIR)\n","sys.path.append(LOCAL_PACKAGE_DIR)\n","\n","from yolo import YOLO"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dBoXEKzEtIFV","colab_type":"code","colab":{}},"source":["# YOLO 클래스는 model_path, achors_path, classes_path를 model_data 밑에 파일로 가짐. 변경을 위해서는 yolo.py 파일에서 YOLO 클래스코드를  직접 변경 필요. \n","\n","print(LOCAL_PACKAGE_DIR)\n","!ls /home/chulmin.kwon45/DLCV/Detection/yolo/keras-yolo3\n","!cat /home/chulmin.kwon45/DLCV/Detection/yolo/keras-yolo3/yolo.py"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ofv6WsJftIFf","colab_type":"text"},"source":["#### YOLO 객체를 사용하기 위한 모델 파일 설정 및 소스 코드 변경\n","* 다크넷에서 Yolo V3 Weight 모델 파일을 다운로드 받은 뒤 이를 keras-yolo3용으로 모델 파일 변경\n","* model_data 디렉토리 밑에 yolo_anchors.txt, coco_classes.txt 가 있는지 확인.\n"]},{"cell_type":"code","metadata":{"id":"NbA_UZOO1eif","colab_type":"code","colab":{}},"source":["!ls /content/DLCV/Detection/yolo/keras-yolo3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MaKsXXuEtIFg","colab_type":"code","colab":{}},"source":["# keras-yolo3 디렉토리 밑에서 아래 명령어로 다크넷에서 Yolov3 weight를 다운로드 받고 이를 keras-yolo3용으로 모델 파일 변경\n","#!wget https://pjreddie.com/media/files/yolov3.weights\n","#!python convert.py yolov3.cfg yolov3.weights model_data/yolo.h5\n","# convert.py를 수행하면 yolo anchor값이 yolo_anchors.txt 파일이 자동으로 생성됨. \n","# coco label과 클래스 매핑은 0부터 매핑함.(0 => person)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jbfjxXfr02GH","colab_type":"code","colab":{}},"source":["# 코랩 버전은 아래를 이용하여 yolov3.weights 파일을 download 받고, convert.py 를 수행하여 model_data 밑에 yolo.h5 파일 생성 수행. \n","%cd /content/DLCV/Detection/yolo/keras-yolo3 \n","# yolo 공식 사이트에서 download시 download 속도가 약 25분 정도 소요됨. 강의 github에서 다운로드 요망. \n","#!wget  https://pjreddie.com/media/files/yolov3.weights\n","# 강의 실습 github에서 다운로드\n","!wget https://github.com/chulminkw/DLCV/releases/download/1.0/yolov3.weights\n","\n","# yolov3.weights를 keras-yolo3에서 사용할 수 있도록 yolo.h5 로 변환\n","!python convert.py yolov3.cfg yolov3.weights model_data/yolo.h5\n","# model_data 밑에 yolo.h5 파일이 생성되었는지 확인. \n","!ls /content/DLCV/Detection/yolo/keras-yolo3/model_data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f8CDi6jL2UxJ","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4FUuvYG6tIFn","colab_type":"code","colab":{}},"source":["import sys\n","import argparse\n","from yolo import YOLO, detect_video\n","#keras-yolo에서 image처리를 주요 PIL로 수행. \n","from PIL import Image\n","\n","# YOLO 객체 생성. config는 default로 keras-yolo3 디렉토리에 있는 yolov3.cfg를 적용. \n","# 코랩 버전은 절대 경로로 각 생성 인자값 입력\n","default_yolo_dir = '/content/DLCV/Detection/yolo'\n","config_dict = {}\n","yolo = YOLO(model_path=os.path.join(default_yolo_dir, 'keras-yolo3/model_data/yolo.h5'),\n","            anchors_path=os.path.join(default_yolo_dir, 'keras-yolo3/model_data/yolo_anchors.txt'),\n","            classes_path=os.path.join(default_yolo_dir, 'keras-yolo3/model_data/coco_classes.txt'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vYHFyCiatIFw","colab_type":"text"},"source":["#### 단일 이미지 Object Detection "]},{"cell_type":"code","metadata":{"id":"UHYjuAuQtIFy","colab_type":"code","colab":{}},"source":["# 원본 이미지 보기 \n","default_dir = '/content/DLCV'\n","img = Image.open(os.path.join(default_dir, 'data/image/beatles01.jpg'))\n","\n","plt.figure(figsize=(12, 12))\n","plt.imshow(img)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hjm4glEAtIF5","colab_type":"code","colab":{}},"source":["# yolo.detect_image() 메소드는 PIL package를 이용하여 image 작업 수행. keras-yolo3/font 디렉토리를 상위 디렉토리로 복사 해야함.  \n","%cd /content/DLCV/Detection/yolo\n","!cp -rf keras-yolo3/font ./font"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pzb3S2ImtIF_","colab_type":"code","colab":{}},"source":["img = Image.open(os.path.join(default_dir, 'data/image/beatles01.jpg'))\n","detected_img = yolo.detect_image(img)\n","\n","plt.figure(figsize=(12, 12))\n","plt.imshow(detected_img)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iX_7ownLtIGF","colab_type":"text"},"source":["### Video Object Detection 수행"]},{"cell_type":"code","metadata":{"id":"OgdhUiNTtIGG","colab_type":"code","colab":{}},"source":["import cv2\n","import time\n","\n","def detect_video_yolo(model, input_path, output_path=\"\"):\n","    \n","    start = time.time()\n","    cap = cv2.VideoCapture(input_path)\n","    \n","    #codec = cv2.VideoWriter_fourcc(*'DIVX')\n","    codec = cv2.VideoWriter_fourcc(*'XVID')\n","    vid_fps = cap.get(cv2.CAP_PROP_FPS)\n","    vid_size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n","    vid_writer = cv2.VideoWriter(output_path, codec, vid_fps, vid_size)\n","    \n","    frame_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    print('총 Frame 갯수:', frame_cnt, '원본 영상 FPS:',vid_fps)\n","    index = 0\n","    while True:\n","        hasFrame, image_frame = cap.read()\n","        if not hasFrame:\n","            print('프레임이 없거나 종료 되었습니다.')\n","            break\n","        start = time.time()\n","        # PIL Package를 내부에서 사용하므로 cv2에서 읽은 image_frame array를 다시 PIL의 Image형태로 변환해야 함.  \n","        image = Image.fromarray(image_frame)\n","        # 아래는 인자로 입력된 yolo객체의 detect_image()로 변환한다.\n","        detected_image = model.detect_image(image)\n","        # cv2의 video writer로 출력하기 위해 다시 PIL의 Image형태를 array형태로 변환 \n","        result = np.asarray(detected_image)\n","        index +=1\n","        print('#### frame:{0} 이미지 처리시간:{1}'.format(index, round(time.time()-start,3)))\n","        \n","        vid_writer.write(result)\n","    \n","    vid_writer.release()\n","    cap.release()\n","    print('### Video Detect 총 수행시간:', round(time.time()-start, 5))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"09OTCgBWtIGO","colab_type":"code","colab":{}},"source":["default_dir = '/content/DLCV'\n","detect_video_yolo(yolo, os.path.join(default_dir, 'data/video/Night_Day_Chase.mp4'),\n","                  os.path.join(default_dir, 'data/output/Night_Day_Chase_yolo_01.avi'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_eNq3M0738HX","colab_type":"code","colab":{}},"source":["## colab 버전은 Object Detection 적용된 영상 파일을 google drive에서 download 해야 합니다. 이를 위해 google drive를 colab에 mount 수행. \n","import os, sys \n","from google.colab import drive \n","\n","drive.mount('/content/gdrive')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1g_ZnBiB4nUZ","colab_type":"code","colab":{}},"source":["## colab 버전은 Object Detection 적용된 영상 파일을 google drive에서 download 해야 합니다. \n","## My Drive 디렉토리 이름에 공란이 있으므로 ' '로 묶습니다. \n","!cp /content/DLCV/data/output/Night_Day_Chase_yolo_01.avi '/content/gdrive/My Drive/Night_Day_Chase_yolo_01.avi'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4myNMD8MtIGX","colab_type":"text"},"source":["### tiny Yolo를 이용하여 이미지와 영상 object detection 수행. \n","* tiny yolo weights파일은 https://pjreddie.com/media/files/yolov3-tiny.weights 에서 다운로드 받을 수 있음. \n","* 다운로드 받은 tiny-yolo weight파일을 keras-yolo3에서 사용할 수 있게 Convert 수행 후 YOLO객체에서 로딩하여 사용 "]},{"cell_type":"code","metadata":{"id":"IXQ3IJSCtIGa","colab_type":"code","colab":{}},"source":["# wget https://pjreddie.com/media/files/yolov3-tiny.weights\n","#!python convert.py yolov3-tiny.cfg ./model_data/yolov3-tiny.weights model_data/yolo-tiny.h5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YYfCssHQ4iiX","colab_type":"code","colab":{}},"source":["# 코랩 버전은 아래를 이용하여 yolov3-tiny.weights 파일을 download 받고, convert.py 를 수행하여 model_data 밑에 yolo-tiny.h5 파일 생성 수힝. \n","%cd /content/DLCV/Detection/yolo/keras-yolo3 \n","!wget https://pjreddie.com/media/files/yolov3-tiny.weights\n","!python convert.py yolov3-tiny.cfg yolov3-tiny.weights model_data/yolo-tiny.h5\n","# model_data 밑에 yolo-tiny.h5 파일이 생성되었는지 확인. \n","!ls /content/DLCV/Detection/yolo/keras-yolo3/model_data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iwpPJYUCtIGp","colab_type":"text"},"source":["#### tiny yolo weight 파일과 anchor 파일, coco 클래스 파일을 YOLO 객체 생성 시 인자로 입력"]},{"cell_type":"code","metadata":{"id":"dhFiGcEmtIGr","colab_type":"code","colab":{}},"source":["default_yolo_dir = '/content/DLCV/Detection/yolo'\n","config_dict = {}\n","\n","tiny_yolo = YOLO(model_path=os.path.join(default_yolo_dir,'keras-yolo3/model_data/yolo-tiny.h5'),\n","            anchors_path=os.path.join(default_yolo_dir,'keras-yolo3/model_data/tiny_yolo_anchors.txt'),\n","            classes_path=os.path.join(default_yolo_dir,'keras-yolo3/model_data/coco_classes.txt'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wc5kJPTetIG3","colab_type":"text"},"source":["#### 단일 이미지 Object Detection"]},{"cell_type":"code","metadata":{"id":"A0jnOQJ3tIG5","colab_type":"code","colab":{}},"source":["default_dir = '/content/DLCV'\n","img = Image.open(os.path.join(default_dir, 'data/image/beatles01.jpg'))\n","detected_img = tiny_yolo.detect_image(img)\n","\n","plt.figure(figsize=(12, 12))\n","plt.imshow(detected_img)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aFVcZvxctIHD","colab_type":"text"},"source":["#### Video Object Detection"]},{"cell_type":"code","metadata":{"id":"57RKvexNtIHD","colab_type":"code","colab":{}},"source":["default_dir = '/content/DLCV'\n","detect_video_yolo(tiny_yolo, os.path.join(default_dir, 'data/video/Night_Day_Chase.mp4'), os.path.join(default_dir, 'data/output/Night_Day_Chase_tiny_yolo01.avi'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AQSZAScK6U0T","colab_type":"code","colab":{}},"source":["## colab 버전은 Object Detection 적용된 영상 파일을 google drive에서 download 해야 합니다. 이를 위해 google drive를 colab에 mount 수행. \n","import os, sys \n","from google.colab import drive \n","\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KD5hifVchOmN","colab_type":"code","colab":{}},"source":["## colab 버전은 Object Detection 적용된 영상 파일을 google drive에서 download 해야 합니다. \n","## My Drive 디렉토리 이름에 공란이 있으므로 ' '로 묶습니다. \n","!cp /content/DLCV/data/output/Night_Day_Chase_tiny_yolo01.avi '/content/gdrive/My Drive/Night_Day_Chase_tiny_yolo01.avi'"],"execution_count":null,"outputs":[]}]}