{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python [conda env:tf115]","language":"python","name":"conda-env-tf115-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"},"colab":{"name":"Esri_Object_Detection_Challenge_colab.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Sr0YRnhoVboE","colab_type":"text"},"source":["###### Esri Challenge\n","* 항공 사진 이미지를 기반으로 자동차와 수영장을 Object Detection"]},{"cell_type":"markdown","metadata":{"id":"HuWx37mCV-Ca","colab_type":"text"},"source":["### 본 실습 예제는 GPU를 활용하므로 상단 메뉴에서 런타임->런타임 유형 변경에서 GPU를 선택해 주십시요.\n","\n","### tensorflow, keras 설치 및 강의 실습코드/데이터 Download\n","\n","Colab 버전은 colab에서 pip 명령어를 이용하여 tensorflow 1.15, keras 2.3를 소스코드 커널 기동시 마다 설치해야 합니다\n","\n","Colab의 tensorflow는 2020년 기준으로 2.2 이며, keras는 2.3입니다. 실습코드는 tensorflow 1.13과 1.15, keras 2.2 기준으로 되어 있으므로 이를 downgrade해야 합니다.\n","\n","pip를 이용하여 tensorflow 1.15을 설치하면 자동으로 downgrade 됩니다.\n","\n","OpenCV는 Colab에서 이미 설치 되어 있으니 추가설치는 필요 없습니다.\n","\n","강의 실습코드와 데이터는 https://github.com/chulminkw/DLCV.git 에서 다운로드 할 수 있습니다. "]},{"cell_type":"code","metadata":{"id":"WsV6YgNwWE3O","colab_type":"code","colab":{}},"source":["# 현재 디렉토리는 /content이며 이 디렉토리를 기준으로 실습코드와 데이터를 다운로드 합니다. \n","!pwd\n","!rm -rf DLCV\n","!git clone https://github.com/chulminkw/DLCV.git\n","# DLCV 디렉토리가 Download되고 DLCV 밑에 Detection과 Segmentation 디렉토리가 있는 것을 확인\n","!ls -lia \n","!ls -lia DLCV\n","\n","# tensorflow 1.15을 설치합니다. 자동으로 tensorflow 2.2가 1.15으로 downgrade 됩니다. \n","!pip install tensorflow-gpu==1.15.2 \n","# keras 2.3를 설치합니다. \n","!pip install keras==2.3.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kdEu8kOsWbYH","colab_type":"code","colab":{}},"source":["# tensorflow는 1.15, keras는 2.3 버전 확인\n","import tensorflow as tf\n","import keras\n","\n","print(tf.__version__)\n","print(keras.__version__)\n","\n","# gpu가 세팅되어 있는지 확인. \n","tf.test.gpu_device_name()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a-Z6nsoXOJjK","colab_type":"text"},"source":["#### keras-retinanet 다운로드 및 설치\n","* fizyr keras-retinanet이 현재 keras 2.4 로 마이그레이션 되면서 버그가 많아짐.\n","* tensorflow 1.15와 호환되는 keras-retinanet 버전(v0.5.1) 다운로드를 https://github.com/chulminkw/keras-retinanet-tf115.git 에서 수행.\n","* /content/DLCV/Detection/retina/keras-retinanet 디렉토리에 download 되고 설치 됩니다. "]},{"cell_type":"code","metadata":{"id":"Z4tUJ3ukWgHd","colab_type":"code","colab":{}},"source":["# keras-retinanet 다운로드 \n","%cd /content/DLCV/Detection/retina\n","!rm -rf /content/DLCV/Detection/retina/keras-retinanet\n","# fizyr keras-retinanet이 현재 keras 2.4 로 마이그레이션 되면서 버그가 많아짐.\n","#  tensorflow 1.15와 호환되는 keras-retinanet 버전(v0.5.1) 다운로드를 https://github.com/chulminkw/keras-retinanet-tf115.git 에서 수행. \n","!git clone https://github.com/chulminkw/keras-retinanet-tf115.git keras-retinanet\n","\n","#  https://github.com/chulminkw/keras-retinanet-tf115.git에서 download받은 keras-retinanet 설치\n","%cd /content/DLCV/Detection/retina/keras-retinanet\n","!echo \"##### installing keras-retinanet\"\n","!pip install . --user\n","!python setup.py build_ext --inplace"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ieh_lo2uj3dL","colab_type":"code","colab":{}},"source":["# 아래 import로 keras-retinanet이 정상적으로 설치되어 있는지 확인. 특히 backbone 함수 체크. \n","import tensorflow as tf\n","\n","from keras_retinanet import models\n","from keras_retinanet.models import backbone\n","\n","b = backbone('resnet50')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XQ7Vyag8atEQ","colab_type":"text"},"source":["#### Esti Dataset 다운로드. \n","해당 데이터는 kaggle이 아닌 강의 실습 코드 github에서 다운로드 "]},{"cell_type":"code","metadata":{"id":"Z_IYAGQUYrJi","colab_type":"code","colab":{}},"source":["# Esti Dataset 다운로드. 해당 압축 데이터는 kaggle이 아닌 강의 실습 코드 github에서 다운로드 \n","%cd /content/DLCV/data\n","!wget https://github.com/chulminkw/DLCV/releases/download/1.0/swimming_pool_and_car.zip\n","# poolncar 디렉토리 생성후 압축 데이터 세트 이동.  \n","!rm -rf poolncar\n","!mkdir poolncar\n","!mv swimming_pool_and_car.zip poolncar\n","# poolncar 디렉토리에 unzip 수행. \n","%cd /content/DLCV/data/poolncar\n","!unzip swimming_pool_and_car.zip > /dev/null 2>&1\n","# images와 annotations 파일의 갯수 조사 \n","!ls -lia /content/DLCV/data/poolncar/training_data/training_data/labels |wc -l\n","!ls -lia /content/DLCV/data/poolncar/training_data/training_data/images |wc -l"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OwX24ZhdVboI","colab_type":"text"},"source":["#### annotation 디렉토리와 image 디렉토리 설정. "]},{"cell_type":"code","metadata":{"id":"lD587ZkXVboL","colab_type":"code","colab":{}},"source":["# annotation과 image 디렉토리 설정. annotation디렉토리에 있는 파일 확인. \n","import os\n","from pathlib import Path\n","# 코렙 버전 수정. \n","#HOME_DIR = str(Path.home())\n","HOME_DIR = '/content'\n","ANNO_DIR = os.path.join(HOME_DIR, 'DLCV/data/poolncar/training_data/training_data/labels')\n","IMAGE_DIR = os.path.join(HOME_DIR, 'DLCV/data/poolncar/training_data/training_data/images')\n","print(ANNO_DIR)\n","\n","files = os.listdir(ANNO_DIR)\n","print('파일 개수는:',len(files))\n","print(files)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XSxF6jVYVboe","colab_type":"text"},"source":["#### XML 형태의 annotation을 csv 형태로 변환\n","* class 명은 1과 2\n","* Object가 작아서 위치 좌표가 소수점까지 표시됨. pixel 단위는 정수형이므로 정수형으로 변환하되 ceil 적용하여 조금 이동하여 변환"]},{"cell_type":"code","metadata":{"id":"kOFZTtG1Vbog","colab_type":"code","colab":{}},"source":["!cat /content/DLCV/data/poolncar/training_data/training_data/labels/000000040.xml"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9FicsJ3TVbot","colab_type":"code","colab":{}},"source":["import glob\n","import pandas as pd\n","import xml.etree.ElementTree as ET\n","import math\n","\n","classes = ['1','2']\n","\n","# XML 파일을 Pandas DataFrame으로 변환 한뒤 DataFrame의 to_csv()를 이용하여 csv 파일로 생성하고 DataFrame반환\n","def xml_to_csv(xml_files, output_filename):\n","    xml_list = []\n","    # xml 확장자를 가진 모든 파일의 절대 경로로 xml_file할당. \n","    for xml_file in xml_files:\n","        # xml 파일을 parsing하여 XML Element형태의 Element Tree를 생성하여 object 정보를 추출. \n","        tree = ET.parse(xml_file)\n","        root = tree.getroot()\n","        \n","        if root.iter('object') is not None:\n","            for obj in root.iter('object'):\n","                full_image_name = os.path.join(IMAGE_DIR, root.find('filename').text)\n","                cls = obj.find('name').text\n","                if cls not in classes:\n","                    continue\n","\n","                xmlbox = obj.find('bndbox')\n","                # 위치 좌표가 소수점까지 표시됨. pixel 단위는 정수형이므로 변환하되 ceil로 조금 이동하여 변환\n","                x1 = math.ceil(float(xmlbox.find('xmin').text))\n","                y1 = math.ceil(float(xmlbox.find('ymin').text))\n","                x2 = math.ceil(float(xmlbox.find('xmax').text))\n","                y2 = math.ceil(float(xmlbox.find('ymax').text))\n","                if x1 == x2 or y1 == y2:\n","                    continue\n","                value = (full_image_name, x1, y1, x2, y2, cls)\n","\n","                # object별 정보를 tuple형태로 xml_list에 저장. \n","                xml_list.append(value)\n","    # 모든 object별 정보를 DataFrame으로 생성하고 이를 CSV 파일로 생성하고 DataFrame은 반환. \n","    column_name = ['filename', 'xmin', 'ymin', 'xmax', 'ymax', 'class']\n","    xml_df = pd.DataFrame(xml_list, columns=column_name)\n","    xml_df.to_csv(output_filename, index=None, header=None)\n","    return xml_df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z8y-zHHuVbo5","colab_type":"text"},"source":["#### train과 validation 용으로 파일 분리. \n","* validation은 약 10% 크기"]},{"cell_type":"code","metadata":{"id":"XfviXKROVbo7","colab_type":"code","colab":{}},"source":["import numpy as np\n","np.random.seed(0)\n","\n","all_xml_files = glob.glob(ANNO_DIR + '/*.xml')\n","file_cnt = len(all_xml_files)\n","valid_size = file_cnt//10\n","valid_index = np.random.choice(file_cnt, valid_size)\n","\n","valid_files = [ all_xml_files[i] for i in valid_index ]\n","train_files = [xml_file for xml_file in all_xml_files if xml_file not in valid_files ]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QBYW1oCiVbpF","colab_type":"text"},"source":["#### CSV 파일로 전체/학습/검증 annotation 저장. "]},{"cell_type":"markdown","metadata":{"id":"saZz-1pPjdXg","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"vIsg2ue3VbpI","colab_type":"code","colab":{}},"source":["# annotation 디렉토리 밑에 csv로 저장\n","all_df = xml_to_csv(all_xml_files, os.path.join(ANNO_DIR, 'poolncar_anno.csv'))\n","train_df = xml_to_csv(train_files, os.path.join(ANNO_DIR, 'poolncar_train_anno.csv'))\n","valid_df = xml_to_csv(valid_files, os.path.join(ANNO_DIR, 'poolncar_valid_anno.csv'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1dVMtJvoVbpR","colab_type":"code","colab":{}},"source":["train_df.shape, valid_df.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JOef7FwfdqyV","colab_type":"code","colab":{}},"source":["# 생성된 annotation csv 파일 확인. \n","!ls /content/DLCV/data/poolncar/training_data/training_data/labels/*.csv"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cS7hD3BuVbpb","colab_type":"text"},"source":["#### class name과 class id 매핑 파일을 ANNO_DIR에 poolncar_class.txt 로 생성\n","* class name은 1(car)과 2(pool)로 되어 있음. id는 0 부터 시작해야 하므로\n","* 1, 0  \n","  2, 1\n","* 코렙 버전은 아래 command 로 생성. "]},{"cell_type":"code","metadata":{"id":"N9P5zzy0Vbpd","colab_type":"code","colab":{}},"source":["# 코렙 버전은 아래 command 로 poolncar_class.txt 파일 생성. \n","%cd /content/DLCV/data/poolncar/training_data/training_data/labels\n","!echo -e \"1, 0\\n2, 0\" > poolncar_class.txt\n","!cat poolncar_class.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4ROO3mxCVbph","colab_type":"code","colab":{}},"source":["import cv2\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","test_image = cv2.imread(os.path.join(HOME_DIR,'DLCV/data/poolncar/training_data/training_data/images/000000040.jpg'))\n","test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n","print(test_image.shape)\n","plt.figure(figsize=(12, 12))\n","plt.imshow(test_image)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ih1oY1t7Vbpq","colab_type":"text"},"source":["### Esri 데이터 세트 학습"]},{"cell_type":"code","metadata":{"id":"j0HwNUdgVbps","colab_type":"code","colab":{}},"source":["import cv2\n","import numpy as np\n","import os\n","from os import listdir, walk\n","import math\n","import tensorflow as tf\n","from os.path import join\n","\n","from keras_retinanet import models\n","from keras_retinanet.bin.train import create_generators,create_models,create_callbacks\n","from keras_retinanet.models import backbone,load_model,convert_model\n","from keras_retinanet.utils.config import read_config_file,parse_anchor_parameters\n","from keras_retinanet.utils.visualization import draw_boxes\n","\n","#from imgaug import augmenters as iaa\n","\n","tf.set_random_seed(31) # SEEDS MAKE RESULTS MORE REPRODUCABLE\n","np.random.seed(17)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"17dC2ni6Vbpx","colab_type":"text"},"source":["#### anchor  box 정보를 config.ini에 저장. \n","* Object 들이 너무 작기 때문에 default anchor로 수행 성능이 저하될 수 있음. \n","* anchor 최적화 스크립트 수행 후 anchor 값을 config.init에 설정할 수 있음. \n","*  Improving RetinaNet for CT Lesion Detection with Dense Masks from Weak RECIST Labels에 사용된 anchor box 최적화 모듈을 https://github.com/martinzlocha/anchor-optimization/ 에서 다운로드 가능 \n","* 여기서는 Winning 솔루션으로 설정된 anchor box를 그대로 사용함. \n","\n","#### Default anchor box 설정\n","sizes   = 32 64 128 256 512\n","strides = 8 16 32 64 128\n","ratios  = 0.5 1 2 3\n","scales  = 1 1.2 1.6\n","\n","#### Winning 솔루션으로 설정된 anchor box , 자동차의 경우 좀더 높이가 강조된 anchor box를 설정. \n","sizes   = 32 64 128 256 512\n","strides = 8 16 32 64 128\n","ratios  = 0.25 0.5 0.75 1 1.5 2 4 6 8 10\n","scales  = 0.5 1 2\n","\n","#### 코랩 버전은 강의 동영상에 있는 anchor-optimization utility를 사용하지 않음. \n"]},{"cell_type":"code","metadata":{"id":"azUBqdCXVbpy","colab_type":"code","colab":{}},"source":["with open(os.path.join('/content/DLCV/Detection/retina','keras-retinanet/snapshots/config_poolncar.ini'),'w') as f:\n","    f.write('[anchor_parameters]\\nsizes   = 32 64 128 256 512\\nstrides = 8 16 32 64 128\\nratios  = 0.25 0.5 0.75 1 1.5 2 4 6 8 10\\nscales  = 0.5 1 2\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zJsuXoVZiIfe","colab_type":"code","colab":{}},"source":["!cat /content/DLCV/Detection/retina/keras-retinanet/snapshots/config_poolncar.ini"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JZiD2sk6Vbp6","colab_type":"text"},"source":["#### 주요 환경 설정\n","* 학습과 검증을 위한 csv annotation설정\n","* backbone은 resnet50\n","* batch_size=8\n","* epochs=35"]},{"cell_type":"code","metadata":{"id":"macZKI9UVbp6","colab_type":"code","colab":{}},"source":["b = backbone('resnet50')\n","files = os.listdir(IMAGE_DIR)\n","\n","class args:\n","    batch_size = 8\n","    # 코랩 버전은 절대 경로로 변경\n","    config = read_config_file(os.path.join('/content/DLCV/Detection/retina','keras-retinanet/snapshots/config_poolncar.ini'))\n","    random_transform =True # Image augmentation\n","    annotations = os.path.join(ANNO_DIR, 'poolncar_train_anno.csv')\n","    #val_annotations = None\n","    val_annotations = os.path.join(ANNO_DIR, 'poolncar_valid_anno.csv')\n","    classes = os.path.join(ANNO_DIR, 'poolncar_class.txt')\n","    # 기본값은 min_side=800, max_side=1333\n","    image_min_side = 672\n","    image_max_side = 672\n","    no_resize=None\n","    dataset_type = 'csv'\n","    tensorboard_dir = ''\n","    evaluation = False\n","    snapshots = True\n","    # 코랩 버전 변경. \n","    snapshot_path = '/content/DLCV/Detection/retina/keras-retinanet/snapshots/poolncar'\n","    backbone = 'resnet50'\n","    # 코랩 버전은 학습 시간이 매우 오래 걸림. Detection 성능이 떨어지더라도 아래 epochs를 10 이하로 조정 검토\n","    epochs = 2\n","    steps = len(files)//(batch_size)\n","    weighted_average = True"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P62iypizVbqC","colab_type":"text"},"source":["#### 학습용 DataGenerator, 검증용 DataGenerator생성"]},{"cell_type":"code","metadata":{"id":"Bsm9d_ydVbqD","colab_type":"code","colab":{}},"source":["train_gen,valid_gen = create_generators(args,b.preprocess_image)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uRxGhBmQVbqI","colab_type":"text"},"source":["#### 학습과 예측 기반 모델 생성\n","* Resnet50 backend 기반 모델 생성하고 이를 반환\n","* 단일 GPU 모델에서는 model과 training_model이 서로 같음"]},{"cell_type":"code","metadata":{"id":"i8RfAVK3VbqJ","colab_type":"code","colab":{}},"source":["model, training_model, prediction_model = create_models(\n","            backbone_retinanet=b.retinanet,\n","            num_classes=train_gen.num_classes(),\n","            weights=None,\n","            multi_gpu=False,\n","            freeze_backbone=True,\n","            lr=1e-3,\n","            config=args.config\n","        )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DXGDNuSoVbqS","colab_type":"text"},"source":["#### callback 생성. "]},{"cell_type":"code","metadata":{"id":"OvjxsCodVbqS","colab_type":"code","colab":{}},"source":["callbacks = create_callbacks(\n","    model,\n","    training_model,\n","    prediction_model,\n","    valid_gen,\n","    args,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xB52awcaVbqW","colab_type":"text"},"source":["#### keras-retinanet으로 pretrained된 coco 모델 다운로드하고 해당 모델을 로드\n","* 앞 예제에서 pretrained 모델을 생성했지만 코렙 버전은 재 생성해야 함. \n","* 코렙 버전은 /content/DLCV/Detection/retina/keras-retinanet/snapshots 디렉토리 밑에 pretrained 모델을 download"]},{"cell_type":"code","metadata":{"id":"Dpxhv4-dlDVw","colab_type":"code","colab":{}},"source":["# 아래 모델은 https://github.com/fizyr/keras-retinanet/releases 에서 download 받을 수 있음. \n","# 해당 모델 h5 파일을 snapshot 디렉토리에 저장 후 retina model의 load_model()을 이용하여 모델 로딩.\n","%cd  /content/DLCV/Detection/retina/keras-retinanet/snapshots\n","!wget https://github.com/fizyr/keras-retinanet/releases/download/0.5.1/resnet50_coco_best_v2.1.0.h5 "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XW34yayGlQA_","colab_type":"text"},"source":["#### training 모델에 최초 weight 로딩은 pretrained된 coco 모델의 weight값으로 로딩"]},{"cell_type":"code","metadata":{"id":"h0jGtSocVbqY","colab_type":"code","colab":{}},"source":["training_model.load_weights('/content/DLCV/Detection/retina/keras-retinanet/snapshots/resnet50_coco_best_v2.1.0.h5',skip_mismatch=True,by_name=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fw2whd6BVbqf","colab_type":"text"},"source":["#### 학습 수행\n","* 주어진 epoch만큼, callback을 적용하며 training 모델의 학습 수행. "]},{"cell_type":"code","metadata":{"id":"JIndgx87Vbqf","colab_type":"code","colab":{}},"source":["# 코렙에서 학습시 약 3시간 30분~4시간 정도 소요됨. \n","training_model.fit_generator(generator=train_gen,\n","        steps_per_epoch=args.steps,\n","        epochs=args.epochs,\n","        verbose=1,\n","        validation_data=valid_gen, \n","        callbacks=callbacks)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AckMGmtfVbqk","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TVJ7cs4XVbqn","colab_type":"text"},"source":["####  convert_model.py를 이용하여 가장 마지막에 학습된 모델을 inference모델로 변환\n","* 코랩 버전은 아래 명령어를 이용하여 inference 모델로 변환"]},{"cell_type":"code","metadata":{"id":"uiVzGRcsVbqp","colab_type":"code","colab":{}},"source":["!ls -lia /content/DLCV/Detection/retina/keras-retinanet/snapshots\n","!chmod +x /content/DLCV/Detection/retina/keras-retinanet/keras_retinanet/bin/convert_model.py\n","!/content/DLCV/Detection/retina/keras-retinanet/keras_retinanet/bin/convert_model.py --config=/content/DLCV/Detection/retina/keras-retinanet/snapshots/config_poolncar.ini /content/DLCV/Detection/retina/keras-retinanet/snapshots/poolncar/resnet50_csv_02.h5 /content/DLCV/Detection/retina/keras-retinanet/snapshots/poolncar/poolncar_inference.h5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7VAm4Rd3Vbqv","colab_type":"code","colab":{}},"source":["# 코렙 버전 디렉토리 수정. \n","model_path = os.path.join('/content/DLCV/Detection/retina/keras-retinanet','snapshots/poolncar/poolncar_inference.h5')\n","print(model_path)\n","# load retinanet model\n","poolncar_retina_model = models.load_model(model_path, backbone_name='resnet50')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ulRW4Bz7Vbqz","colab_type":"text"},"source":["#### 또는 API를 이용하여 가장 마지막에 학습된 모델을 inference모델로 변환"]},{"cell_type":"code","metadata":{"id":"h-mPfZ-FVbq0","colab_type":"code","colab":{}},"source":["import os\n","from os import listdir, walk\n","from os.path import join\n","from keras_retinanet.bin.train import create_models\n","from keras_retinanet.models import backbone,convert_model\n","from keras_retinanet.utils.config import read_config_file,parse_anchor_parameters\n","import numpy as np\n","import keras\n","import math\n","import tensorflow as tf\n","tf.set_random_seed(31)\n","np.random.seed(17)\n","\n","# 코랩 버전 절대 경로 디렉토리 수정. \n","model, training_model, prediction_model = create_models(\n","            backbone_retinanet=backbone('resnet50').retinanet,\n","            num_classes=2,\n","            weights=None,\n","            multi_gpu=False,\n","            freeze_backbone=False,\n","            lr=1e-3,\n","            config=read_config_file('/content/DLCV/Detection/retina/keras-retinanet/snapshots/config_poolncar.ini')\n","        )\n","\n","training_model.load_weights('/content/DLCV/Detection/retina/keras-retinanet/snapshots/poolncar/resnet50_csv_02.h5')\n","poolncar_retina_model = convert_model(training_model,anchor_params=parse_anchor_parameters(read_config_file('/content/DLCV/Detection/retina/keras-retinanet/snapshots/config_poolncar.ini')))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OYJAxTxFVbq5","colab_type":"text"},"source":["#### inference 모델을 이용하여 Object Detection 수행. "]},{"cell_type":"code","metadata":{"id":"BL3AnU7WVbq6","colab_type":"code","colab":{}},"source":["from keras_retinanet.utils.image import read_image_bgr\n","\n","plt.figure(figsize=(12, 12))\n","plt.imshow(cv2.cvtColor(read_image_bgr(os.path.join(IMAGE_DIR, '000000040.jpg')), cv2.COLOR_BGR2RGB))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gL4u7Y9qVbrB","colab_type":"code","colab":{}},"source":["import cv2\n","import time\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n","from keras_retinanet.utils.visualization import draw_box, draw_caption\n","from keras_retinanet.utils.colors import label_color\n","\n","def get_detected_image_retina(model, img_array, convert_RGB=True, is_print=True):\n","    \n","    # copy to draw on\n","    draw = img_array.copy()\n","    if convert_RGB:\n","        draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n","    img_array = preprocess_image(img_array)\n","    # 학습시 사용된 image resize를 적용. \n","    img_array, scale = resize_image(img_array, 672, 672)\n","    \n","    # process image\n","    start = time.time()\n","    boxes, scores, labels = model.predict_on_batch(np.expand_dims(img_array, axis=0))\n","    if is_print:\n","        print(\"object detection 처리 시간: \", round(time.time() - start,5))\n","    \n","    # correct for image scale\n","    boxes /= scale\n","    \n","    classes=['1','2']\n","\n","    # visualize detections\n","    for box, score, label in zip(boxes[0], scores[0], labels[0]):\n","        \n","        # scores are sorted so we can break\n","        print(score)\n","        if score < 0.5:\n","            break\n","\n","        color = label_color(label)\n","\n","        b = box.astype(int)\n","\n","        caption = \"{} {:.3f}\".format(classes[label], score)\n","        print('caption:', caption)\n","        cv2.rectangle(draw, (box[0],box[1]), (box[2], box[3]), color, thickness=2)\n","        cv2.putText(draw, caption, (b[0], b[1] - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n","    \n","    if is_print:\n","        print(\"이미지 processing 시간2: \", round(time.time() - start,5))\n","    \n","    return draw"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uL61zKGcVbrF","colab_type":"code","colab":{}},"source":["img_array  = cv2.imread(os.path.join(IMAGE_DIR, '000000040.jpg'))\n","detected_image = get_detected_image_retina(poolncar_retina_model,img_array, convert_RGB=True, is_print=True)\n","\n","plt.figure(figsize=(12, 12))\n","plt.axis('off')\n","plt.imshow(detected_image)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C-hLI30BVbrN","colab_type":"text"},"source":["#### validation dataset 기반으로 mAP 계산"]},{"cell_type":"code","metadata":{"id":"NYXg3DATVbrO","colab_type":"code","colab":{}},"source":["import os\n","\n","class args:\n","    batch_size=8\n","    dataset_type='csv'\n","    score_threshold=0.05\n","    iou_threshold=0.3\n","    max_detections=100\n","    image_min_side=672\n","    image_max_side=672\n","    config=None\n","    annotations=os.path.join(ANNO_DIR, 'poolncar_valid_anno.csv')\n","    classes=os.path.join(ANNO_DIR, 'poolncar_class.txt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rlY1fxfhVbrR","colab_type":"code","colab":{}},"source":["from keras_retinanet.bin.evaluate import create_generator as eval_create_generator\n","from keras_retinanet.utils.eval import evaluate\n","\n","generator = eval_create_generator(args)\n","\n","average_precisions = evaluate(\n","            generator,\n","            poolncar_retina_model,\n","            iou_threshold=args.iou_threshold,\n","            score_threshold=args.score_threshold,\n","            max_detections=args.max_detections,\n","            save_path=None\n","        )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0nsFoh0oVbrW","colab_type":"code","colab":{}},"source":["# print evaluation\n","total_instances = []\n","precisions = []\n","for label, (average_precision, num_annotations) in average_precisions.items():\n","    print('{:.0f} instances of class'.format(num_annotations),\n","          generator.label_to_name(label), 'with average precision: {:.4f}'.format(average_precision))\n","    total_instances.append(num_annotations)\n","    precisions.append(average_precision)\n","\n","if sum(total_instances) == 0:\n","    print('No test instances found.')\n","\n","print('mAP using the weighted average of precisions among classes: {:.4f}'.format(sum([a * b for a, b in zip(total_instances, precisions)]) / sum(total_instances)))\n","print('mAP: {:.4f}'.format(sum(precisions) / sum(x > 0 for x in total_instances)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ybxhxvF9VbrZ","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}