{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python [conda env:tf113] *","language":"python","name":"conda-env-tf113-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"},"colab":{"name":"SSD_Face_Detection_colab.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"o8Jk2bVjS3eO","colab_type":"text"},"source":["### tensorflow로 Face Detection 수행하기\n","* WiderFace 데이터세트로 Pretrained된 Tensorflow graph 모델을 다운로드 받아 이를 이용해 Face Detection 수행. "]},{"cell_type":"markdown","metadata":{"id":"K80S0jTiTVuW","colab_type":"text"},"source":["### 본 실습 예제는 GPU를 활용하므로 상단 메뉴에서 런타임->런타임 유형 변경에서 GPU를 선택해 주십시요. "]},{"cell_type":"markdown","metadata":{"id":"nNtaRfcgTYeA","colab_type":"text"},"source":["\n","#### tensorflow, keras 설치 및 강의 실습코드/데이터 Download\n","\n","**공지**\n","\n","현재(2020년 8월 11일) Colab에서 GPU 커널 적용시 tensorflow 1.13으로 downgrade가 되지 않습니다. \n","때문에 colab에서는 Segmentation 학습 시 tensorflow 1.15, keras 2.3 을 설치하겠습니다. \n","\n","Colab 버전colab에서 pip 명령어를 이용하여 tensorflow 1.15, keras 2.3를 소스코드 커널 기동시 마다 설치해야 합니다\n","\n","Colab의 tensorflow는 2020년 기준으로 2.2 이며, keras는 2.3입니다. 실습코드는 tensorflow 1.13과 1.15, keras 2.2와 2.3 기준으로 되어 있으므로 이를 downgrade해야 합니다.\n","\n","pip를 이용하여 tensorflow 1.15을 설치하면 자동으로 downgrade 됩니다.\n","\n","OpenCV는 Colab에서 이미 설치 되어 있으니 추가설치는 필요 없습니다.\n","\n","강의 실습코드와 데이터는 https://github.com/chulminkw/DLCV.git 에서 다운로드 할 수 있습니다. "]},{"cell_type":"code","metadata":{"id":"Ibvnfc0WTey0","colab_type":"code","colab":{}},"source":["# 현재 디렉토리는 /content이며 이 디렉토리를 기준으로 실습코드와 데이터를 다운로드 합니다. \n","!pwd\n","!rm -rf DLCV\n","!git clone https://github.com/chulminkw/DLCV.git\n","# DLCV 디렉토리가 Download되고 DLCV 밑에 Detection과 Segmentation 디렉토리가 있는 것을 확인\n","!ls -lia \n","!ls -lia DLCV"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QcYyKCGATxTr","colab_type":"code","colab":{}},"source":["#현재(2020년 8월 11일) Colab에서 GPU 커널 적용시 tensorflow 1.13으로 downgrade가 되지 않습니다. \n","#때문에 colab에서는 Segmentation 학습 시 tensorflow 1.15, keras 2.3 을 설치하겠습니다.\n","# tensorflow 1.15을 설치합니다. 자동으로 tensorflow 2.2가 1.15로 downgrade 됩니다. \n","!pip install tensorflow-gpu==1.15.2 \n","# keras 2.3를 설치합니다. \n","!pip install keras==2.3.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JlwEMvFnUSq4","colab_type":"code","colab":{}},"source":["# tensorflow 1.15과 keras 2.3 version 확인.  \n","import tensorflow as tf\n","import keras\n","\n","print(tf.__version__)\n","print(keras.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"epzmIeBdS3eS","colab_type":"text"},"source":["#### Tensorflow Face Detector\n","* Github : https://github.com/yeephycho/tensorflow-face-detection\n","* SSD + MobileNet기반으로 Pretrained된 모델 다운로드 \n","* https://github.com/yeephycho/tensorflow-face-detection/raw/master/model/frozen_inference_graph_face.pb"]},{"cell_type":"code","metadata":{"id":"Zdy5kDXYUuvw","colab_type":"code","colab":{}},"source":["### 코랩 버전은 아래를 이용하여 다시 pretrained 모델을 다운로드 받아야 합니다."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bap29pEbUf-6","colab_type":"code","colab":{}},"source":["!rm -rf /content/DLCV/Detection/ssd//pretrained\n","!mkdir /content/DLCV/Detection/ssd/pretrained\n","# pretrained 디렉토리가 생성되었는지 확인 합니다. \n","%cd /content/DLCV/Detection/ssd\n","!ls\n","\n","### coco 데이터 세트로 pretrained 된 ssd 파일과 config용 graph pbtxt 다운로드 \n","%cd /content/DLCV/Detection/ssd/pretrained\n","!echo \"##### downloading pretrained ssd face weight file\"\n","!wget https://github.com/yeephycho/tensorflow-face-detection/raw/master/model/frozen_inference_graph_face.pb\n","\n","!echo \"##### check out pretrained ssd face weight file\"\n","!ls /content/DLCV/Detection/ssd/pretrained"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qChc4EOmTsJC","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E--Zu_pdS3eV","colab_type":"text"},"source":["#### SSD + Mobilenet Pretrained된 모델 로딩하여 Face  Detection"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"Z2AqMzpBS3eZ","colab_type":"code","colab":{}},"source":["import numpy as np\n","import tensorflow as tf\n","import cv2\n","import time\n","import matplotlib.pyplot as plt\n","import os\n","%matplotlib inline\n","\n","#코랩 버전은 default_dir과 default_rcnn_dir 절대 경로를 이용합니다. os.path.join()으로 상세 파일/디렉토리를 지정합니다. \n","default_dir = '/content/DLCV'\n","default_ssd_dir='/content/DLCV/Detection/ssd'\n","\n","#inference graph를 읽음. .\n","with tf.gfile.FastGFile(os.path.join(default_ssd_dir, 'pretrained/frozen_inference_graph_face.pb'), 'rb') as f:\n","    graph_def = tf.GraphDef()\n","    graph_def.ParseFromString(f.read())\n","    \n","with tf.Session() as sess:\n","    # Session 시작하고 inference graph 모델 로딩 \n","    sess.graph.as_default()\n","    tf.import_graph_def(graph_def, name='')\n","    \n","    # 입력 이미지 생성 및 BGR을 RGB로 변경 \n","    img = cv2.imread(os.path.join(default_dir, 'data/image/EPL01.jpg'))\n","    draw_img = img.copy()\n","    rows = img.shape[0]\n","    cols = img.shape[1]\n","    inp = cv2.resize(img, (300, 300))\n","    # OpenCV로 입력받은 BGR 이미지를 RGB 이미지로 변환 \n","    inp = inp[:, :, [2, 1, 0]] \n","\n","    start = time.time()\n","    # Object Detection 수행. \n","    out = sess.run([sess.graph.get_tensor_by_name('num_detections:0'),\n","                    sess.graph.get_tensor_by_name('detection_scores:0'),\n","                    sess.graph.get_tensor_by_name('detection_boxes:0'),\n","                    sess.graph.get_tensor_by_name('detection_classes:0')],\n","                   feed_dict={'image_tensor:0': inp.reshape(1, inp.shape[0], inp.shape[1], 3)})\n","    \n","    green_color=(0, 255, 0)\n","    red_color=(0, 0, 255)\n","    \n","    # Bounding Box 시각화 \n","    # Detect된 Object 별로 bounding box 시각화 \n","    num_detections = int(out[0][0])\n","    for i in range(num_detections):\n","        # class id와 object class score, bounding box정보를 추출\n","        classId = int(out[3][0][i])\n","        score = float(out[1][0][i])\n","        bbox = [float(v) for v in out[2][0][i]]\n","        if score > 0.4:\n","            left = bbox[1] * cols\n","            top = bbox[0] * rows\n","            right = bbox[3] * cols\n","            bottom = bbox[2] * rows\n","            # cv2의 rectangle(), putText()로 bounding box의 클래스명 시각화 \n","            cv2.rectangle(draw_img, (int(left), int(top)), (int(right), int(bottom)), green_color, thickness=2)\n","            caption = \"face: {:.4f}\".format(score)\n","            print(caption)\n","            cv2.putText(draw_img, caption, (int(left), int(top - 5)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, red_color, 2)\n","    \n","    print('Detection 수행시간:',round(time.time() - start, 2),\"초\")\n","    \n","img_rgb = cv2.cvtColor(draw_img, cv2.COLOR_BGR2RGB)\n","\n","plt.figure(figsize=(12, 12))\n","plt.imshow(img_rgb)\n","        "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BsjYUe5hS3et","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Vm9C6QaS3e3","colab_type":"code","colab":{}},"source":["def get_tensor_detected_image(sess, img_array, use_copied_array):\n","    \n","    rows = img_array.shape[0]\n","    cols = img_array.shape[1]\n","    if use_copied_array:\n","        draw_img = img_array.copy()\n","    else:\n","        draw_img = img_array\n","    \n","    inp = cv2.resize(img_array, (300, 300))\n","    inp = inp[:, :, [2, 1, 0]]  # BGR2RGB\n","    \n","    start = time.time()\n","    # Object Detection 수행. \n","    out = sess.run([sess.graph.get_tensor_by_name('num_detections:0'),\n","                    sess.graph.get_tensor_by_name('detection_scores:0'),\n","                    sess.graph.get_tensor_by_name('detection_boxes:0'),\n","                    sess.graph.get_tensor_by_name('detection_classes:0')],\n","                   feed_dict={'image_tensor:0': inp.reshape(1, inp.shape[0], inp.shape[1], 3)})\n","    \n","    green_color=(0, 255, 0)\n","    red_color=(0, 0, 255)\n","    \n","    # Bounding Box 시각화 \n","    # Detect된 Object 별로 bounding box 시각화 \n","    num_detections = int(out[0][0])\n","    for i in range(num_detections):\n","        # class id와 object class score, bounding box정보를 추출\n","        classId = int(out[3][0][i])\n","        score = float(out[1][0][i])\n","        bbox = [float(v) for v in out[2][0][i]]\n","        if score > 0.4:\n","            left = bbox[1] * cols\n","            top = bbox[0] * rows\n","            right = bbox[3] * cols\n","            bottom = bbox[2] * rows\n","            # cv2의 rectangle(), putText()로 bounding box의 클래스명 시각화 \n","            cv2.rectangle(draw_img, (int(left), int(top)), (int(right), int(bottom)), green_color, thickness=2)\n","            caption = \"face: {:.4f}\".format(score)\n","            cv2.putText(draw_img, caption, (int(left), int(top - 5)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, red_color, 2)\n","    \n","    print('Detection 수행시간:',round(time.time() - start, 3),\"초\")\n","    return draw_img\n","\n","#코랩 버전은 default_dir과 default_rcnn_dir 절대 경로를 이용합니다. os.path.join()으로 상세 파일/디렉토리를 지정합니다. \n","default_dir = '/content/DLCV'\n","default_ssd_dir='/content/DLCV/Detection/ssd'\n","\n","#inference graph를 읽음. .\n","with tf.gfile.FastGFile(os.path.join(default_ssd_dir, 'pretrained/frozen_inference_graph_face.pb'), 'rb') as f:\n","    graph_def = tf.GraphDef()\n","    graph_def.ParseFromString(f.read())\n","    \n","with tf.Session() as sess:\n","    # Session 시작하고 inference graph 모델 로딩 \n","    sess.graph.as_default()\n","    tf.import_graph_def(graph_def, name='')\n","    \n","    # 입력 이미지 생성, Object Detection된 image 반환, 반환된 image의 BGR을 RGB로 변경 \n","    img = cv2.imread(os.path.join(default_dir, 'data/image/EPL01.jpg'))\n","    draw_img = get_tensor_detected_image(sess, img, True)\n","\n","img_rgb = cv2.cvtColor(draw_img, cv2.COLOR_BGR2RGB)\n","\n","plt.figure(figsize=(12, 12))\n","plt.imshow(img_rgb)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6zOdyNyUS3fE","colab_type":"text"},"source":["#### tensorflow로 SSD+ Inception 기반 video Object Detection 수행"]},{"cell_type":"code","metadata":{"id":"5czxoG5-XbKp","colab_type":"code","colab":{}},"source":["# 코랩 버전은 아래 코드를 이용합니다.\n","from IPython.display import HTML\n","from base64 import b64encode\n","mp4 = open('/content/DLCV/data/video/InfiniteWar01.mp4','rb').read()\n","data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","HTML(\"\"\"\n","<video width=800 controls>\n","      <source src=\"%s\" type=\"video/mp4\">\n","</video>\n","\"\"\" % data_url)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Y2ok-4RS3fR","colab_type":"code","colab":{}},"source":["default_dir = '/content/DLCV'\n","default_ssd_dir='/content/DLCV/Detection/ssd'\n","\n","\n","video_input_path = os.path.join(default_dir, 'data/video/InfiniteWar01.mp4')\n","# linux에서 video output의 확장자는 반드시 avi 로 설정 필요. \n","video_output_path = os.path.join(default_dir, 'data/output/InfiniteWar01_ssd.avi')\n","\n","cap = cv2.VideoCapture(video_input_path)\n","\n","codec = cv2.VideoWriter_fourcc(*'XVID')\n","\n","vid_size = (round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n","vid_fps = cap.get(cv2.CAP_PROP_FPS)\n","    \n","vid_writer = cv2.VideoWriter(video_output_path, codec, vid_fps, vid_size) \n","\n","frame_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","print('총 Frame 갯수:', frame_cnt, 'FPS:', vid_fps )\n","\n","green_color=(0, 255, 0)\n","red_color=(0, 0, 255)\n","\n","# SSD+Inception inference graph를 읽음. .\n","with tf.gfile.FastGFile(os.path.join(default_ssd_dir, 'pretrained/frozen_inference_graph_face.pb'), 'rb') as f:\n","    graph_def = tf.GraphDef()\n","    graph_def.ParseFromString(f.read())\n","    \n","with tf.Session() as sess:\n","    # Session 시작하고 inference graph 모델 로딩 \n","    sess.graph.as_default()\n","    tf.import_graph_def(graph_def, name='')\n","    index = 0\n","    while True:\n","        hasFrame, img_frame = cap.read()\n","        if not hasFrame:\n","            print('더 이상 처리할 frame이 없습니다.')\n","            break\n","\n","        draw_img_frame = get_tensor_detected_image(sess, img_frame, False)\n","        vid_writer.write(draw_img_frame)\n","    # end of while loop\n","\n","vid_writer.release()\n","cap.release()  \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TUpTOziVddR_","colab_type":"code","colab":{}},"source":["## colab 버전은 Object Detection 적용된 영상 파일을 google drive에서 download 해야 합니다. 이를 위해 google drive를 colab에 mount 수행. \n","import os, sys \n","from google.colab import drive \n","\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oMTWZpbpdfWb","colab_type":"code","colab":{}},"source":["## colab 버전은 Object Detection 적용된 영상 파일을 google drive에서 download 해야 합니다. \n","## My Drive 디렉토리 이름에 공란이 있으므로 ' '로 묶습니다. \n","!cp /content/DLCV/data/output/InfiniteWar01_ssd.avi '/content/gdrive/My Drive/InfiniteWar01_ssd.avi'\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WItT1vK-S3fm","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}