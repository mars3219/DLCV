{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python [conda env:tf113] *","language":"python","name":"conda-env-tf113-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"},"colab":{"name":"OpenCV_FasterRCNN_ObjectDetection_colab.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"yjWKB2ypoGPi","colab_type":"text"},"source":["### OpenCV DNN 패키지를 이용하여 Faster R-CNN 기반의 Object Detection 수행\n","* Tensorflow 에서 Pretrained 된 모델 파일을 OpenCV에서 로드하여 이미지와 영상에 대한 Object Detection 수행. "]},{"cell_type":"markdown","metadata":{"id":"wVNfnyKTsUQ0","colab_type":"text"},"source":["# 아래는 OpenCV 실습 예제이므로 GPU가 필요하지 않으며 코랩 커널을 GPU로 바꿀 필요가 없습니다. \n","* tensorflow와 keras 설치는 필요하지 않습니다.\n","* OpenCV와 기타 필요한 패키지는 이미 코랩에 설치 되어 있습니다.  "]},{"cell_type":"markdown","metadata":{"id":"V8cTewbuVr5K","colab_type":"text"},"source":["#### 실습 코드를 github에서 다운로드"]},{"cell_type":"code","metadata":{"id":"WAP9awgzpGgC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1596186802177,"user_tz":-540,"elapsed":3338,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"6637f8b3-3edd-4f21-b4d6-b035cc99e3c9"},"source":["# 현재 디렉토리는 /content이며 이 디렉토리를 기준으로 실습코드와 데이터를 다운로드 합니다. \n","!pwd"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2YD_JraNpGq6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":149},"executionInfo":{"status":"ok","timestamp":1596186808332,"user_tz":-540,"elapsed":9480,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"8e60229f-fe7c-4fcf-ace8-146cd990be9a"},"source":["!git clone https://github.com/chulminkw/DLCV.git"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Cloning into 'DLCV'...\n","remote: Enumerating objects: 56, done.\u001b[K\n","remote: Counting objects:   1% (1/56)\u001b[K\rremote: Counting objects:   3% (2/56)\u001b[K\rremote: Counting objects:   5% (3/56)\u001b[K\rremote: Counting objects:   7% (4/56)\u001b[K\rremote: Counting objects:   8% (5/56)\u001b[K\rremote: Counting objects:  10% (6/56)\u001b[K\rremote: Counting objects:  12% (7/56)\u001b[K\rremote: Counting objects:  14% (8/56)\u001b[K\rremote: Counting objects:  16% (9/56)\u001b[K\rremote: Counting objects:  17% (10/56)\u001b[K\rremote: Counting objects:  19% (11/56)\u001b[K\rremote: Counting objects:  21% (12/56)\u001b[K\rremote: Counting objects:  23% (13/56)\u001b[K\rremote: Counting objects:  25% (14/56)\u001b[K\rremote: Counting objects:  26% (15/56)\u001b[K\rremote: Counting objects:  28% (16/56)\u001b[K\rremote: Counting objects:  30% (17/56)\u001b[K\rremote: Counting objects:  32% (18/56)\u001b[K\rremote: Counting objects:  33% (19/56)\u001b[K\rremote: Counting objects:  35% (20/56)\u001b[K\rremote: Counting objects:  37% (21/56)\u001b[K\rremote: Counting objects:  39% (22/56)\u001b[K\rremote: Counting objects:  41% (23/56)\u001b[K\rremote: Counting objects:  42% (24/56)\u001b[K\rremote: Counting objects:  44% (25/56)\u001b[K\rremote: Counting objects:  46% (26/56)\u001b[K\rremote: Counting objects:  48% (27/56)\u001b[K\rremote: Counting objects:  50% (28/56)\u001b[K\rremote: Counting objects:  51% (29/56)\u001b[K\rremote: Counting objects:  53% (30/56)\u001b[K\rremote: Counting objects:  55% (31/56)\u001b[K\rremote: Counting objects:  57% (32/56)\u001b[K\rremote: Counting objects:  58% (33/56)\u001b[K\rremote: Counting objects:  60% (34/56)\u001b[K\rremote: Counting objects:  62% (35/56)\u001b[K\rremote: Counting objects:  64% (36/56)\u001b[K\rremote: Counting objects:  66% (37/56)\u001b[K\rremote: Counting objects:  67% (38/56)\u001b[K\rremote: Counting objects:  69% (39/56)\u001b[K\rremote: Counting objects:  71% (40/56)\u001b[K\rremote: Counting objects:  73% (41/56)\u001b[K\rremote: Counting objects:  75% (42/56)\u001b[K\rremote: Counting objects:  76% (43/56)\u001b[K\rremote: Counting objects:  78% (44/56)\u001b[K\rremote: Counting objects:  80% (45/56)\u001b[K\rremote: Counting objects:  82% (46/56)\u001b[K\rremote: Counting objects:  83% (47/56)\u001b[K\rremote: Counting objects:  85% (48/56)\u001b[K\rremote: Counting objects:  87% (49/56)\u001b[K\rremote: Counting objects:  89% (50/56)\u001b[K\rremote: Counting objects:  91% (51/56)\u001b[K\rremote: Counting objects:  92% (52/56)\u001b[K\rremote: Counting objects:  94% (53/56)\u001b[K\rremote: Counting objects:  96% (54/56)\u001b[K\rremote: Counting objects:  98% (55/56)\u001b[K\rremote: Counting objects: 100% (56/56)\u001b[K\rremote: Counting objects: 100% (56/56), done.\u001b[K\n","remote: Compressing objects: 100% (52/52), done.\u001b[K\n","remote: Total 145 (delta 17), reused 0 (delta 0), pack-reused 89\u001b[K\n","Receiving objects: 100% (145/145), 127.44 MiB | 45.01 MiB/s, done.\n","Resolving deltas: 100% (38/38), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"84RqCN7dpGxx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":300},"executionInfo":{"status":"ok","timestamp":1596186813283,"user_tz":-540,"elapsed":12697,"user":{"displayName":"권철민","photoUrl":"","userId":"03917677622451543916"}},"outputId":"a23365b5-acad-4382-f417-1017e22782bb"},"source":["# DLCV 디렉토리가 Download되고 DLCV 밑에 Detection과 Segmentation 디렉토리가 있는 것을 확인\n","!ls -lia \n","!ls -lia DLCV"],"execution_count":3,"outputs":[{"output_type":"stream","text":["total 20\n","4194328 drwxr-xr-x 1 root root 4096 Jul 31 09:13 .\n","4208237 drwxr-xr-x 1 root root 4096 Jul 31 09:12 ..\n","4194329 drwxr-xr-x 1 root root 4096 Jul 28 16:16 .config\n","4208329 drwxr-xr-x 6 root root 4096 Jul 31 09:13 DLCV\n","1310744 drwxr-xr-x 1 root root 4096 Jul 10 16:29 sample_data\n","total 160\n","4208329 drwxr-xr-x 6 root root   4096 Jul 31 09:13 .\n","4194328 drwxr-xr-x 1 root root   4096 Jul 31 09:13 ..\n","4208406 drwxr-xr-x 6 root root   4096 Jul 31 09:13 data\n","4208372 drwxr-xr-x 8 root root   4096 Jul 31 09:13 Detection\n","4208357 -rw-r--r-- 1 root root 134412 Jul 31 09:13 DLCV_Colab_SrcCode.zip\n","4208330 drwxr-xr-x 8 root root   4096 Jul 31 09:13 .git\n","4208398 -rw-r--r-- 1 root root    142 Jul 31 09:13 README.md\n","4208399 drwxr-xr-x 3 root root   4096 Jul 31 09:13 Segmentation\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pxGzGTihoGPn","colab_type":"text"},"source":["#### 입력 이미지로 사용될 이미지 보기"]},{"cell_type":"code","metadata":{"id":"bnG40bxIoGPq","colab_type":"code","colab":{}},"source":["import cv2\n","import matplotlib.pyplot as plt\n","import os\n","%matplotlib inline\n","\n","# 코랩 버전은 상대 경로를 사용하지 않습니다. /content 디렉토리를 기준으로 절대 경로를 이용합니다. \n","# default_dir 은 /content/DLCV로 지정하고 os.path.join()으로 상세 파일/디렉토리를 지정합니다. \n","default_dir = '/content/DLCV'\n","img = cv2.imread(os.path.join(default_dir,'data/image/beatles01.jpg'))\n","img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","\n","print('image shape:', img.shape)\n","plt.figure(figsize=(12, 12))\n","plt.imshow(img_rgb)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2-8u8Lh-oGQC","colab_type":"text"},"source":["#### Tensorflow에서 Pretrained 된 Inference모델(Frozen graph)와 환경파일을 다운로드 받은 후 이를 이용해 OpenCV에서 Inference 모델 생성\n","* https://github.com/opencv/opencv/wiki/TensorFlow-Object-Detection-API 에 다운로드 URL 있음.\n","* pretrained 모델은 http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet50_coco_2018_01_28.tar.gz 에서 다운로드 후 압축 해제\n","* pretrained 모델을 위한 환경 파일은 https://github.com/opencv/opencv_extra/blob/master/testdata/dnn/faster_rcnn_resnet50_coco_2018_01_28.pbtxt 에서 다운로드 \n","* download된 모델 파일과 config 파일을 인자로 하여 inference 모델을 DNN에서 로딩함. \n"]},{"cell_type":"code","metadata":{"id":"Hu-QTZ3poGQF","colab_type":"code","colab":{}},"source":["#코랩 버전은 OS 터미널이 아닌 코랩 Cell 에서 os command를 수행해야 합니다. \n","#아래 command는 코랩에서 OS 명령어를 통해 fast_rcnn/pretrained 디렉토리를 만듭니다. \n","\n","!rm -rf /content/DLCV/Detection/fast_rcnn/pretrained\n","!mkdir /content/DLCV/Detection/fast_rcnn/pretrained\n","# pretrained 디렉토리가 생성되었는지 확인 합니다. \n","%cd /content/DLCV/Detection/fast_rcnn\n","!ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uzAOJUBfTyfM","colab_type":"code","colab":{}},"source":["### coco 데이터 세트로 pretrained 된 faster rcnn weight 파일과 config용 graph pbtxt 다운로드 \n","%cd /content/DLCV/Detection/fast_rcnn/pretrained\n","!echo \"##### downloading pretrained weight file and config pbtxt file\"\n","!wget http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet50_coco_2018_01_28.tar.gz\n","!wget https://raw.githubusercontent.com/opencv/opencv_extra/master/testdata/dnn/faster_rcnn_resnet50_coco_2018_01_28.pbtxt\n","\n","# tar 파일 압축 해제\n","!echo \"##### uncompressing tar file\"\n","!tar -xvf faster_rcnn*.gz\n","\n","# config용 pbtxt 파일의 이름을 graph.pbtxt로 변경\n","# echo \"renaming pbtxt file name\"\n","!mv /content/DLCV/Detection/fast_rcnn/pretrained/faster_rcnn*.pbtxt /content/DLCV/Detection/fast_rcnn/pretrained/faster_rcnn_resnet50_coco_2018_01_28/graph.pbtxt\n","\n","# tar 파일 삭제\n","!echo \"##### deleting tar file\" \n","!rm *.gz\n","\n","# weight파일과 config 파일이 있는 pretrained/faster_rcnn_resnet50_coco_2018_01_28 디렉토리 내부 확인 \n","!echo \"##### check out pretrained/faster_rcnn_resnet50_coco_2018_01_28\"\n","!ls /content/DLCV/Detection/fast_rcnn/pretrained/faster_rcnn_resnet50_coco_2018_01_28"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3BR1jZzjoGQd","colab_type":"text"},"source":["#### dnn에서 readNetFromTensorflow()로 tensorflow inference 모델을 로딩"]},{"cell_type":"code","metadata":{"id":"olI2JWHPoGQh","colab_type":"code","colab":{}},"source":["#코랩 버전은 default_rcnn_dir 절대 경로를 이용합니다. os.path.join()으로 상세 파일/디렉토리를 지정합니다. \n","default_rcnn_dir='/content/DLCV/Detection/fast_rcnn'\n","cv_net = cv2.dnn.readNetFromTensorflow(os.path.join(default_rcnn_dir, 'pretrained/faster_rcnn_resnet50_coco_2018_01_28/frozen_inference_graph.pb'), \n","                                     os.path.join(default_rcnn_dir, 'pretrained/faster_rcnn_resnet50_coco_2018_01_28/graph.pbtxt'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HHU0pNwKoGQq","colab_type":"text"},"source":["#### coco 데이터 세트의 클래스id별 클래스명 지정. "]},{"cell_type":"code","metadata":{"id":"u3ECqcSdoGQs","colab_type":"code","colab":{}},"source":["# OpenCV Yolo용 \n","labels_to_names_seq = {0:'person',1:'bicycle',2:'car',3:'motorbike',4:'aeroplane',5:'bus',6:'train',7:'truck',8:'boat',9:'traffic light',10:'fire hydrant',\n","                        11:'stop sign',12:'parking meter',13:'bench',14:'bird',15:'cat',16:'dog',17:'horse',18:'sheep',19:'cow',20:'elephant',\n","                        21:'bear',22:'zebra',23:'giraffe',24:'backpack',25:'umbrella',26:'handbag',27:'tie',28:'suitcase',29:'frisbee',30:'skis',\n","                        31:'snowboard',32:'sports ball',33:'kite',34:'baseball bat',35:'baseball glove',36:'skateboard',37:'surfboard',38:'tennis racket',39:'bottle',40:'wine glass',\n","                        41:'cup',42:'fork',43:'knife',44:'spoon',45:'bowl',46:'banana',47:'apple',48:'sandwich',49:'orange',50:'broccoli',\n","                        51:'carrot',52:'hot dog',53:'pizza',54:'donut',55:'cake',56:'chair',57:'sofa',58:'pottedplant',59:'bed',60:'diningtable',\n","                        61:'toilet',62:'tvmonitor',63:'laptop',64:'mouse',65:'remote',66:'keyboard',67:'cell phone',68:'microwave',69:'oven',70:'toaster',\n","                        71:'sink',72:'refrigerator',73:'book',74:'clock',75:'vase',76:'scissors',77:'teddy bear',78:'hair drier',79:'toothbrush' }"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UhHCdi2YoGQ5","colab_type":"code","colab":{}},"source":["labels_to_names_0 = {0:'person',1:'bicycle',2:'car',3:'motorcycle',4:'airplane',5:'bus',6:'train',7:'truck',8:'boat',9:'traffic light',\n","                    10:'fire hydrant',11:'street sign',12:'stop sign',13:'parking meter',14:'bench',15:'bird',16:'cat',17:'dog',18:'horse',19:'sheep',\n","                    20:'cow',21:'elephant',22:'bear',23:'zebra',24:'giraffe',25:'hat',26:'backpack',27:'umbrella',28:'shoe',29:'eye glasses',\n","                    30:'handbag',31:'tie',32:'suitcase',33:'frisbee',34:'skis',35:'snowboard',36:'sports ball',37:'kite',38:'baseball bat',39:'baseball glove',\n","                    40:'skateboard',41:'surfboard',42:'tennis racket',43:'bottle',44:'plate',45:'wine glass',46:'cup',47:'fork',48:'knife',49:'spoon',\n","                    50:'bowl',51:'banana',52:'apple',53:'sandwich',54:'orange',55:'broccoli',56:'carrot',57:'hot dog',58:'pizza',59:'donut',\n","                    60:'cake',61:'chair',62:'couch',63:'potted plant',64:'bed',65:'mirror',66:'dining table',67:'window',68:'desk',69:'toilet',\n","                    70:'door',71:'tv',72:'laptop',73:'mouse',74:'remote',75:'keyboard',76:'cell phone',77:'microwave',78:'oven',79:'toaster',\n","                    80:'sink',81:'refrigerator',82:'blender',83:'book',84:'clock',85:'vase',86:'scissors',87:'teddy bear',88:'hair drier',89:'toothbrush',\n","                    90:'hair brush'}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LXfz6Wl3oGRE","colab_type":"code","colab":{}},"source":["labels_to_names = {1:'person',2:'bicycle',3:'car',4:'motorcycle',5:'airplane',6:'bus',7:'train',8:'truck',9:'boat',10:'traffic light',\n","                    11:'fire hydrant',12:'street sign',13:'stop sign',14:'parking meter',15:'bench',16:'bird',17:'cat',18:'dog',19:'horse',20:'sheep',\n","                    21:'cow',22:'elephant',23:'bear',24:'zebra',25:'giraffe',26:'hat',27:'backpack',28:'umbrella',29:'shoe',30:'eye glasses',\n","                    31:'handbag',32:'tie',33:'suitcase',34:'frisbee',35:'skis',36:'snowboard',37:'sports ball',38:'kite',39:'baseball bat',40:'baseball glove',\n","                    41:'skateboard',42:'surfboard',43:'tennis racket',44:'bottle',45:'plate',46:'wine glass',47:'cup',48:'fork',49:'knife',50:'spoon',\n","                    51:'bowl',52:'banana',53:'apple',54:'sandwich',55:'orange',56:'broccoli',57:'carrot',58:'hot dog',59:'pizza',60:'donut',\n","                    61:'cake',62:'chair',63:'couch',64:'potted plant',65:'bed',66:'mirror',67:'dining table',68:'window',69:'desk',70:'toilet',\n","                    71:'door',72:'tv',73:'laptop',74:'mouse',75:'remote',76:'keyboard',77:'cell phone',78:'microwave',79:'oven',80:'toaster',\n","                    81:'sink',82:'refrigerator',83:'blender',84:'book',85:'clock',86:'vase',87:'scissors',88:'teddy bear',89:'hair drier',90:'toothbrush',\n","                    91:'hair brush'}\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J0cNEXuaoGRL","colab_type":"text"},"source":["#### 이미지를 preprocessing 수행하여 Network에 입력하고 Object Detection 수행 후 결과를 이미지에 시각화 "]},{"cell_type":"code","metadata":{"id":"mVd6UfosoGRM","colab_type":"code","colab":{}},"source":["# 원본 이미지가 Faster RCNN기반 네트웍으로 입력 시 resize됨. \n","# resize된 이미지 기반으로 bounding box 위치가 예측 되므로 이를 다시 원복하기 위해 원본 이미지 shape정보 필요\n","rows = img.shape[0]\n","cols = img.shape[1]\n","# cv2의 rectangle()은 인자로 들어온 이미지 배열에 직접 사각형을 업데이트 하므로 그림 표현을 위한 별도의 이미지 배열 생성. \n","draw_img = img.copy()\n","\n","# 원본 이미지 배열 BGR을 RGB로 변환하여 배열 입력. Tensorflow Faster RCNN은 size를 고정할 필요가 없는 것으로 추정. \n","cv_net.setInput(cv2.dnn.blobFromImage(img, swapRB=True, crop=False))\n","\n","# Object Detection 수행하여 결과를 cvOut으로 반환 \n","cv_out = cv_net.forward()\n","print(cv_out.shape)\n","\n","# bounding box의 테두리와 caption 글자색 지정\n","green_color=(0, 255, 0)\n","red_color=(0, 0, 255)\n","\n","# detected 된 object들을 iteration 하면서 정보 추출\n","for detection in cv_out[0,0,:,:]:\n","    score = float(detection[2])\n","    class_id = int(detection[1])\n","    # detected된 object들의 score가 0.5 이상만 추출\n","    if score > 0.5:\n","        # detected된 object들은 scale된 기준으로 예측되었으므로 다시 원본 이미지 비율로 계산\n","        left = detection[3] * cols\n","        top = detection[4] * rows\n","        right = detection[5] * cols\n","        bottom = detection[6] * rows\n","        # labels_to_names_seq 딕셔너리로 class_id값을 클래스명으로 변경.\n","        caption = \"{}: {:.4f}\".format(labels_to_names_0[class_id], score)\n","        print(caption)\n","        #cv2.rectangle()은 인자로 들어온 draw_img에 사각형을 그림. 위치 인자는 반드시 정수형.\n","        cv2.rectangle(draw_img, (int(left), int(top)), (int(right), int(bottom)), color=green_color, thickness=2)\n","        cv2.putText(draw_img, caption, (int(left), int(top - 5)), cv2.FONT_HERSHEY_SIMPLEX, 0.4, red_color, 1)\n","\n","img_rgb = cv2.cvtColor(draw_img, cv2.COLOR_BGR2RGB)\n","\n","plt.figure(figsize=(12, 12))\n","plt.imshow(img_rgb)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ghXipK5BoGRY","colab_type":"text"},"source":["#### 단일 이미지의 object detection을 함수로 생성"]},{"cell_type":"code","metadata":{"id":"522oCQjvoGRZ","colab_type":"code","colab":{}},"source":["import time\n","\n","def get_detected_img(cv_net, img_array, score_threshold, use_copied_array=True, is_print=True):\n","    \n","    rows = img_array.shape[0]\n","    cols = img_array.shape[1]\n","    \n","    draw_img = None\n","    if use_copied_array:\n","        draw_img = img_array.copy()\n","    else:\n","        draw_img = img_array\n","    \n","    cv_net.setInput(cv2.dnn.blobFromImage(img_array, swapRB=True, crop=False))\n","    \n","    start = time.time()\n","    cv_out = cv_net.forward()\n","    \n","    green_color=(0, 255, 0)\n","    red_color=(0, 0, 255)\n","\n","    # detected 된 object들을 iteration 하면서 정보 추출\n","    for detection in cv_out[0,0,:,:]:\n","        score = float(detection[2])\n","        class_id = int(detection[1])\n","        # detected된 object들의 score가 함수 인자로 들어온 score_threshold 이상만 추출\n","        if score > score_threshold:\n","            # detected된 object들은 scale된 기준으로 예측되었으므로 다시 원본 이미지 비율로 계산\n","            left = detection[3] * cols\n","            top = detection[4] * rows\n","            right = detection[5] * cols\n","            bottom = detection[6] * rows\n","            # labels_to_names 딕셔너리로 class_id값을 클래스명으로 변경. opencv에서는 class_id + 1로 매핑해야함.\n","            caption = \"{}: {:.4f}\".format(labels_to_names_0[class_id], score)\n","            print(caption)\n","            #cv2.rectangle()은 인자로 들어온 draw_img에 사각형을 그림. 위치 인자는 반드시 정수형.\n","            cv2.rectangle(draw_img, (int(left), int(top)), (int(right), int(bottom)), color=green_color, thickness=2)\n","            cv2.putText(draw_img, caption, (int(left), int(top - 5)), cv2.FONT_HERSHEY_SIMPLEX, 0.4, red_color, 1)\n","    if is_print:\n","        print('Detection 수행시간:',round(time.time() - start, 2),\"초\")\n","\n","    return draw_img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o-lwmpcuoGRk","colab_type":"code","colab":{}},"source":["# image 로드 \n","#코랩 버전은 default_dir, default_rcnn_dir 절대 경로를 이용합니다. os.path.join()으로 상세 파일/디렉토리를 지정합니다. \n","img = cv2.imread(os.path.join(default_dir,'data/image/beatles01.jpg'))\n","print('image shape:', img.shape)\n","\n","# tensorflow inference 모델 로딩\n","cv_net = cv2.dnn.readNetFromTensorflow(os.path.join(default_rcnn_dir, 'pretrained/faster_rcnn_resnet50_coco_2018_01_28/frozen_inference_graph.pb'), \n","                                     os.path.join(default_rcnn_dir, 'pretrained/faster_rcnn_resnet50_coco_2018_01_28/graph.pbtxt'))\n","# Object Detetion 수행 후 시각화 \n","draw_img = get_detected_img(cv_net, img, score_threshold=0.5, use_copied_array=True, is_print=True)\n","\n","img_rgb = cv2.cvtColor(draw_img, cv2.COLOR_BGR2RGB)\n","\n","plt.figure(figsize=(12, 12))\n","plt.imshow(img_rgb)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MdmvUY58oGRr","colab_type":"code","colab":{}},"source":["# image 로드 \n","#코랩 버전은 default_dir, default_rcnn_dir 절대 경로를 이용합니다. os.path.join()으로 상세 파일/디렉토리를 지정합니다. \n","default_dir = '/content/DLCV'\n","img = cv2.imread(os.path.join(default_dir,'data/image/baseball01.jpg'))\n","print('image shape:', img.shape)\n","\n","# tensorflow inference 모델 로딩\n","cv_net = cv2.dnn.readNetFromTensorflow(os.path.join(default_rcnn_dir, 'pretrained/faster_rcnn_resnet50_coco_2018_01_28/frozen_inference_graph.pb'), \n","                                     os.path.join(default_rcnn_dir, 'pretrained/faster_rcnn_resnet50_coco_2018_01_28/graph.pbtxt'))\n","# Object Detetion 수행 후 시각화 \n","draw_img = get_detected_img(cv_net, img, score_threshold=0.5, use_copied_array=True, is_print=True)\n","\n","img_rgb = cv2.cvtColor(draw_img, cv2.COLOR_BGR2RGB)\n","\n","plt.figure(figsize=(12, 12))\n","plt.imshow(img_rgb)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ATCJmCM4oGR4","colab_type":"text"},"source":["### Video Object Detection 수행"]},{"cell_type":"markdown","metadata":{"id":"X6m7Apb9oGR5","colab_type":"text"},"source":["#### 원본 영상 보기"]},{"cell_type":"code","metadata":{"id":"UBgisqn9WbQl","colab_type":"code","colab":{}},"source":["# 코랩 버전은 아래 코드를 이용합니다.\n","from IPython.display import HTML\n","from base64 import b64encode\n","mp4 = open('/content/DLCV/data/video/John_Wick_small.mp4','rb').read()\n","data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","HTML(\"\"\"\n","<video width=800 controls>\n","      <source src=\"%s\" type=\"video/mp4\">\n","</video>\n","\"\"\" % data_url)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kLRgevpdoGSE","colab_type":"text"},"source":["#### VideoCapture와 VideoWriter 설정하기\n","* VideoCapture를 이용하여 Video를 frame별로 capture 할 수 있도록 설정\n","* VideoCapture의 속성을 이용하여 Video Frame의 크기 및 FPS 설정. \n","* VideoWriter를 위한 인코딩 코덱 설정 및 영상 write를 위한 설정 "]},{"cell_type":"code","metadata":{"id":"N1tZcag0oGSG","colab_type":"code","colab":{}},"source":["import os\n","\n","#코랩 버전은 default_dir 절대 경로를 이용합니다.\n","default_dir = '/content/DLCV'\n","\n","video_input_path = os.path.join(default_dir, 'data/video/John_Wick_small.mp4')\n","# linux에서 video output의 확장자는 반드시 avi 로 설정 필요. \n","video_output_path = os.path.join(default_dir, 'data/output/John_Wick_small_cv01.avi')\n","\n","cap = cv2.VideoCapture(video_input_path)\n","\n","codec = cv2.VideoWriter_fourcc(*'XVID')\n","\n","vid_size = (round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))) \n","vid_fps = cap.get(cv2.CAP_PROP_FPS )\n","    \n","vid_writer = cv2.VideoWriter(video_output_path, codec, vid_fps, vid_size) \n","\n","frame_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","print('총 Frame 갯수:', frame_cnt)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_UH6nhqeoGSM","colab_type":"text"},"source":["##### 총 Frame 별로 iteration 하면서 Object Detection 수행. 개별 frame별로 단일 이미지 Object Detection과 유사 "]},{"cell_type":"code","metadata":{"id":"eDHC5DWmoGSO","colab_type":"code","colab":{}},"source":["# bounding box의 테두리와 caption 글자색 지정\n","green_color=(0, 255, 0)\n","red_color=(0, 0, 255)\n","\n","while True:\n","\n","    hasFrame, img_frame = cap.read()\n","    if not hasFrame:\n","        print('더 이상 처리할 frame이 없습니다.')\n","        break\n","\n","    rows = img_frame.shape[0]\n","    cols = img_frame.shape[1]\n","    # 원본 이미지 배열 BGR을 RGB로 변환하여 배열 입력\n","    cv_net.setInput(cv2.dnn.blobFromImage(img_frame,  swapRB=True, crop=False))\n","    \n","    start= time.time()\n","    # Object Detection 수행하여 결과를 cv_out으로 반환 \n","    cv_out = cv_net.forward()\n","    frame_index = 0\n","    # detected 된 object들을 iteration 하면서 정보 추출\n","    for detection in cv_out[0,0,:,:]:\n","        score = float(detection[2])\n","        class_id = int(detection[1])\n","        # detected된 object들의 score가 0.5 이상만 추출\n","        if score > 0.5:\n","            # detected된 object들은 scale된 기준으로 예측되었으므로 다시 원본 이미지 비율로 계산\n","            left = detection[3] * cols\n","            top = detection[4] * rows\n","            right = detection[5] * cols\n","            bottom = detection[6] * rows\n","            # labels_to_names_0딕셔너리로 class_id값을 클래스명으로 변경.\n","            caption = \"{}: {:.4f}\".format(labels_to_names_0[class_id], score)\n","            #print(class_id, caption)\n","            #cv2.rectangle()은 인자로 들어온 draw_img에 사각형을 그림. 위치 인자는 반드시 정수형.\n","            cv2.rectangle(img_frame, (int(left), int(top)), (int(right), int(bottom)), color=green_color, thickness=2)\n","            cv2.putText(img_frame, caption, (int(left), int(top - 5)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, red_color, 1)\n","    print('Detection 수행 시간:', round(time.time()-start, 2),'초')\n","    vid_writer.write(img_frame)\n","# end of while loop\n","\n","vid_writer.release()\n","cap.release()   "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gp7M1Z26XDJH","colab_type":"code","colab":{}},"source":["## colab 버전은 Object Detection 적용된 영상 파일을 google drive에서 download 해야 합니다. 이를 위해 google drive를 colab에 mount 수행. \n","import os, sys \n","from google.colab import drive \n","\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ePboa4kvWWbQ","colab_type":"code","colab":{}},"source":["!ls /content/gdrive"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bdZH4xQ2oGSX","colab_type":"code","colab":{}},"source":["## colab 버전은 Object Detection 적용된 영상 파일을 google drive에서 download 해야 합니다. \n","## My Drive 디렉토리 이름에 공란이 있으므로 ' '로 묶습니다. \n","!cp /content/DLCV/data/output/John_Wick_small_cv01.avi '/content/gdrive/My Drive/John_Wick_small_cv01.avi'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PQPbuwpRoGSb","colab_type":"text"},"source":["#### video detection 전용 함수 생성. "]},{"cell_type":"code","metadata":{"id":"S9yIBDEuoGSc","colab_type":"code","colab":{}},"source":["def do_detected_video(cv_net, input_path, output_path, score_threshold, is_print):\n","    \n","    cap = cv2.VideoCapture(input_path)\n","\n","    codec = cv2.VideoWriter_fourcc(*'XVID')\n","\n","    vid_size = (round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n","    vid_fps = cap.get(cv2.CAP_PROP_FPS)\n","\n","    vid_writer = cv2.VideoWriter(output_path, codec, vid_fps, vid_size) \n","\n","    frame_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    print('총 Frame 갯수:', frame_cnt)\n","\n","    green_color=(0, 255, 0)\n","    red_color=(0, 0, 255)\n","    while True:\n","        hasFrame, img_frame = cap.read()\n","        if not hasFrame:\n","            print('더 이상 처리할 frame이 없습니다.')\n","            break\n","        \n","        img_frame = get_detected_img(cv_net, img_frame, score_threshold=score_threshold, use_copied_array=False, is_print=is_print)\n","        \n","        vid_writer.write(img_frame)\n","    # end of while loop\n","\n","    vid_writer.release()\n","    cap.release()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AkGqygCioGSk","colab_type":"code","colab":{}},"source":["#코랩 버전은 default_dir 절대 경로를 이용합니다.\n","default_dir = '/content/DLCV'\n","\n","do_detected_video(cv_net, os.path.join(default_dir, 'data/video/John_Wick_small.mp4'), os.path.join(default_dir,'data/output/John_Wick_small_02.avi'), 0.2, True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"paS6igCod2Ka","colab_type":"code","colab":{}},"source":["!cp /content/DLCV/data/output/John_Wick_small_02.avi '/content/gdrive/My Drive/John_Wick_small_02.avi'"],"execution_count":null,"outputs":[]}]}