{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python [conda env:tf113] *","language":"python","name":"conda-env-tf113-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"},"colab":{"name":"Balloon_데이터세트_학습및_Segmentation_colab.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"KV26ZGG1GA4l","colab_type":"text"},"source":["### Matterport 패키지를 이용하여 Balloon 데이터 세트를 학습하고 이를 기반으로 Segmentation 적용\n","* Matterport 패키지의 학습 프로세스를 상세히 설명."]},{"cell_type":"markdown","metadata":{"id":"MHQyMTenGXCY","colab_type":"text"},"source":["### 본 실습 예제는 GPU를 활용하므로 상단 메뉴에서 런타임->런타임 유형 변경에서 GPU를 선택해 주십시요. \n","\n","tensorflow, keras 설치 및 강의 실습코드/데이터 Download\n","\n","**공지**\n","\n","현재(2020년 8월 11일) Colab에서 GPU 커널 적용시 tensorflow 1.13으로 downgrade가 되지 않습니다. \n","때문에 colab에서는 Segmentation 학습 시 tensorflow 1.15, keras 2.3 을 설치하겠습니다. \n","\n","Colab 버전colab에서 pip 명령어를 이용하여 tensorflow 1.15, keras 2.3를 소스코드 커널 기동시 마다 설치해야 합니다\n","\n","Colab의 tensorflow는 2020년 기준으로 2.2 이며, keras는 2.3입니다. 실습코드는 tensorflow 1.13과 1.15, keras 2.2와 2.3 기준으로 되어 있으므로 이를 downgrade해야 합니다.\n","\n","pip를 이용하여 tensorflow 1.15을 설치하면 자동으로 downgrade 됩니다.\n","\n","OpenCV는 Colab에서 이미 설치 되어 있으니 추가설치는 필요 없습니다.\n","\n","강의 실습코드와 데이터는 https://github.com/chulminkw/DLCV.git 에서 다운로드 할 수 있습니다. "]},{"cell_type":"code","metadata":{"id":"0lED3cS6Gf7I","colab_type":"code","colab":{}},"source":["# 현재 디렉토리는 /content이며 이 디렉토리를 기준으로 실습코드와 데이터를 다운로드 합니다. \n","!pwd\n","!git clone https://github.com/chulminkw/DLCV.git\n","# DLCV 디렉토리가 Download되고 DLCV 밑에 Detection과 Segmentation 디렉토리가 있는 것을 확인\n","!ls -lia \n","!ls -lia DLCV\n","\n","# tensorflow 1.15을 설치합니다. 자동으로 tensorflow 2.2가 1.15로 downgrade 됩니다. \n","!pip install tensorflow-gpu==1.15.2 \n","# keras 2.3를 설치합니다. \n","!pip install keras==2.3.0\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wXdjSVB5G47h","colab_type":"code","colab":{}},"source":["# tensorflow는 1.15, keras는 2.3 버전 확인\n","# GPU가 세팅되어 있지 않으면 상단 메뉴에서 런타임->런타임 유형 변경에서 GPU를 선택한 후 런타임 다시 시작을 선택하고 처음 부터인 tensorflow, keras 설치 부터 다시 시작. \n","import tensorflow as tf\n","import keras\n","\n","print(tf.__version__)\n","print(keras.__version__)\n","\n","# gpu가 세팅되어 있는지 확인. \n","tf.test.gpu_device_name()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KN5TuR2vHFUA","colab_type":"text"},"source":["#### Matterport Mask RCNN 패키지 다운로드 \n","\n","#### 중요\n","Mask_RCNN은 현재 (2020년 8월 11일 기준) tensorflow 1.15 적용시 소스 코드의 변경이 필요합니다.\n","\n","아래에서 Mask_RCNN.git 설치 후 기존 mrcnn/model.py를 삭제하고 아래와 같이 새로운 소스코드를 https://raw.githubusercontent.com/rteuwens/Mask_RCNN/master/mrcnn/model.py 에서 다운로드 받은 후에 설치 필요. "]},{"cell_type":"code","metadata":{"id":"3m2sALqp9-tt","colab_type":"code","colab":{}},"source":["# Mask_RCNN 다운로드 \n","%cd /content/DLCV/Segmentation/mask_rcnn\n","!git clone https://github.com/matterport/Mask_RCNN.git\n","\n","# 중요.아래에서 Mask_RCNN.git 설치 후 기존 mrcnn/model.py를 삭제하고 \n","# 아래와 같이 새로운 소스코드를 https://raw.githubusercontent.com/rteuwens/Mask_RCNN/master/mrcnn/model.py 에서 다운로드 받은 후에 설치 필요.  \n","%cd /content/DLCV/Segmentation/mask_rcnn/Mask_RCNN/mrcnn\n","!rm model.py\n","!wget https://raw.githubusercontent.com/rteuwens/Mask_RCNN/master/mrcnn/model.py"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LXobn8djSwfk","colab_type":"text"},"source":["#### Mask_RCNN 패키지 설치"]},{"cell_type":"code","metadata":{"id":"Xrtpe-JJG7v_","colab_type":"code","colab":{}},"source":["# 다운로드한 Mask_RCNN 디렉토리로 이동하여 Mask_RCNN 패키지 설치. \n","%cd /content/DLCV/Segmentation/mask_rcnn/Mask_RCNN\n","#!pip install -r requirements.txt\n","!python setup.py install"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GlyFZyYlGA4q","colab_type":"code","colab":{}},"source":["import os\n","import sys\n","import itertools\n","import math\n","import logging\n","import json\n","import re\n","import random\n","from collections import OrderedDict\n","\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","import matplotlib.lines as lines\n","from matplotlib.patches import Polygon\n","import cv2\n","\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3kIyooJZGA5D","colab_type":"code","colab":{}},"source":["from mrcnn import utils\n","from mrcnn import visualize\n","from mrcnn.visualize import display_images\n","import mrcnn.model as modellib\n","from mrcnn.model import log"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wD6yqkqZGA5d","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WRmf8ZZ_GA5v","colab_type":"text"},"source":["#### 주요 수행 모듈인 balloon 모듈을 setup 하여 import하지 않고, 소스코드에서 바로 import 수행.\n","##### 이를 위해 PATH에 balloon.py 파일이 있는 디렉토리를 지정하고 import 를 적용"]},{"cell_type":"code","metadata":{"id":"R9DuWBBwGA51","colab_type":"code","colab":{}},"source":["#Mask_RCNN 패키지의 samples/balloon 디렉토리의 balloon.py 를 import 한다. \n","# 코랩 버전 수정. \n","#ROOT_DIR = os.path.abspath(\".\")\n","ROOT_DIR = '/content/DLCV/Segmentation/mask_rcnn'\n","sys.path.append(os.path.join(ROOT_DIR, \"Mask_RCNN/samples/balloon/\"))\n","\n","import balloon"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GJq_EFNDGA6H","colab_type":"text"},"source":["#### balloon 모듈은 어떠한 API들로 구성되어 있는지 직접 소스코드에서 확인. "]},{"cell_type":"code","metadata":{"id":"tRSVJ1pkGA6K","colab_type":"code","colab":{}},"source":["!cat \"/content/DLCV/Segmentation/mask_rcnn/Mask_RCNN/samples/balloon/balloon.py\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i_ieWLPGGA6a","colab_type":"text"},"source":["#### balloon 데이터 세트가 제대로 되어 있는지 확인.  train과 val 서브 디렉토리가 ./Mask_RCNN/dataset/balloon 에 존재해야 함. "]},{"cell_type":"code","metadata":{"id":"CkIBPP61K1Hw","colab_type":"code","colab":{}},"source":["!cd .."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dkZQG0amJcvp","colab_type":"code","colab":{}},"source":["%cd /content/DLCV/data\n","!rm -rf balloon*\n","!wget https://github.com/matterport/Mask_RCNN/releases/download/v2.1/balloon_dataset.zip\n","!unzip balloon_dataset.zip\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rTRNMVCBL4ul","colab_type":"code","colab":{}},"source":["%cd /content/DLCV/data/balloon\n","!ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7sqKaIvgGA6d","colab_type":"code","colab":{}},"source":["import subprocess\n","from pathlib import Path\n","\n","#HOME_DIR = str(Path.home())\n","HOME_DIR = '/content'\n","BALLOON_DATA_DIR = os.path.join(HOME_DIR, \"DLCV/data/balloon\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mMQZkJhDGA6p","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nZbCq6TqGA6z","colab_type":"text"},"source":["#### balloon 모듈에 설정된 Config 셋업. GPU 갯수, Batch시 image갯수가 사전 설정 되어 있음. "]},{"cell_type":"code","metadata":{"id":"Bw7CBk1SGA62","colab_type":"code","colab":{}},"source":["config = balloon.BalloonConfig()\n","config.display()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ljYKUakOGA7E","colab_type":"text"},"source":["#### balloon 모듈에서 balloon 데이터 세트 로딩. "]},{"cell_type":"code","metadata":{"scrolled":true,"id":"9JEfhBdxGA7H","colab_type":"code","colab":{}},"source":["# Dataset을 로딩. \n","\n","dataset = balloon.BalloonDataset()\n","dataset.load_balloon(BALLOON_DATA_DIR, \"train\")\n","\n","# Must call before using the dataset\n","dataset.prepare()\n","\n","print(\"Image Count: {}\".format(len(dataset.image_ids)))\n","print(\"Class Count: {}\".format(dataset.num_classes))\n","for i, info in enumerate(dataset.class_info):\n","    print(\"{:3}. {:50}\".format(i, info['name']))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tWVWzNVIGA7T","colab_type":"text"},"source":["#### balloon 모듈에서 로딩한 balloon 데이터 세트의 세부 정보 확인. "]},{"cell_type":"code","metadata":{"id":"ehvav7xWGA7W","colab_type":"code","colab":{}},"source":["# dataset의 image_info는 리스트 객체이며 내부 원소로 이미지별 세부 정보를 딕셔너리로 가지고 있음. \n","# dataset의 image_ids 는 이미지의 고유 id나 이름이 아니라 dataset에서 이미지의 상세 정보를 관리하기 위한 리스트 인덱스에 불과 \n","\n","print('#### balloon 데이터 세트 이미지의 인덱스 ID들 ####')\n","print(dataset.image_ids)\n","print('\\n ##### balloon 데이터 세트의 이미지 정보들 ####')\n","print(dataset.image_info)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xpXGtuoeGA7k","colab_type":"text"},"source":["#### polygon 정보 확인"]},{"cell_type":"code","metadata":{"id":"Ie_cY6XFGA7n","colab_type":"code","colab":{}},"source":["image_28 = dataset.image_info[28]\n","polygons = image_28['polygons']\n","polygon_x = polygons[0]['all_points_x']\n","polygon_y = polygons[0]['all_points_y']\n","print(len(polygon_x))\n","print('polygon_x:', polygon_x, 'polygon_y:',polygon_y)\n","\n","polygon_xy = [(x, y) for (x, y) in zip(polygon_x, polygon_y)]\n","print('polygon_xy:', polygon_xy)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"arMt27pHGA8B","colab_type":"code","colab":{}},"source":["image_28_array = cv2.imread(os.path.join(BALLOON_DATA_DIR,'train/'+image_28['id']))\n","for position in polygon_xy:\n","    cv2.circle(image_28_array, position, 3, (255, 0, 0), -1)\n","\n","plt.figure(figsize=(8, 8))\n","plt.axis('off')    \n","plt.imshow(image_28_array)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bhptCxWuGA8N","colab_type":"code","colab":{}},"source":["np.random.seed(99)\n","# Load and display random samples\n","image_ids = np.random.choice(dataset.image_ids, 4)\n","print('image_ids:', image_ids)\n","for image_id in image_ids:\n","    image = dataset.load_image(image_id)\n","    # 지정된 image_id에 있는 mask 를 로딩하고 시각화를 위한 mask정보들과 대상 클래스 ID들을 추출\n","    mask, class_ids = dataset.load_mask(image_id)\n","    #원본 데이터와 여러개의 클래스들에 대해 Mask를 시각화 하되, 가장 top 클래스에 대해서는 클래스명까지 추출. 나머지는 배경\n","    visualize.display_top_masks(image, mask, class_ids, dataset.class_names)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HWge1M_xGA8b","colab_type":"code","colab":{}},"source":["image = dataset.load_image(28)\n","print(image.shape)\n","print(image_28['polygons'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EI57nmckGA8p","colab_type":"text"},"source":["#### polygon 형태의 데이터를 boolean mask 형태로 변환"]},{"cell_type":"code","metadata":{"id":"35y20yS9GA8r","colab_type":"code","colab":{}},"source":["import skimage\n","\n","img = np.zeros((10, 10), dtype=np.uint8)\n","r = np.array([1, 2, 8])\n","c = np.array([1, 7, 4])\n","print('img:', img)\n","# r과 c로 지정된 인덱스에 있는 img 값만 1로 설정함. \n","rr, cc = skimage.draw.polygon(r, c)\n","img[rr, cc] = 1\n","print('row positions:',rr, 'column positions:',cc)\n","print('0, 1로 masking된 img:\\n',img)\n","print('Boolean형태로 masking된 img:\\n',img.astype(np.bool))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WQpH3EF4GA83","colab_type":"code","colab":{}},"source":["mask, class_ids = dataset.load_mask(28)\n","print(\"mask shape:\", mask.shape, \"class_ids:\", class_ids)\n","print(mask)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SCrWgQ1FGA9A","colab_type":"code","colab":{}},"source":["image = dataset.load_image(28)\n","mask, class_ids = dataset.load_mask(28)\n","visualize.display_top_masks(image, mask, class_ids, dataset.class_names)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WAJZR-M-GA9K","colab_type":"text"},"source":["#### ballon 데이터 세트의 image정보, 클래스 정보, mask 정보의 추출과 변환을 위한 BallonDataset 생성"]},{"cell_type":"code","metadata":{"id":"hhzXOJkhGA9M","colab_type":"code","colab":{}},"source":["class BalloonDataset(utils.Dataset):\n","\n","    def load_balloon(self, dataset_dir, subset):\n","        \"\"\"Load a subset of the Balloon dataset.\n","        dataset_dir: Root directory of the dataset.\n","        subset: Subset to load: train or val\n","        \"\"\"\n","        # 클래스 id와 클래스명 등록은 Dataset의 add_class()를 이용. \n","        self.add_class(\"balloon\", 1, \"balloon\")\n","\n","        # train또는 val 용도의 Dataset 생성만 가능. \n","        assert subset in [\"train\", \"val\"]\n","        dataset_dir = os.path.join(dataset_dir, subset)\n","        \n","        # json 형태의 annotation을 로드하고 파싱. \n","        annotations = json.load(open(os.path.join(dataset_dir, \"via_region_data.json\")))\n","        annotations = list(annotations.values())  # don't need the dict keys\n","        \n","        annotations = [a for a in annotations if a['regions']]\n","\n","        # Add images\n","        for a in annotations:\n","            # Get the x, y coordinaets of points of the polygons that make up\n","            # the outline of each object instance. These are stores in the\n","            # shape_attributes (see json format above)\n","            # The if condition is needed to support VIA versions 1.x and 2.x.\n","            if type(a['regions']) is dict:\n","                polygons = [r['shape_attributes'] for r in a['regions'].values()]\n","            else:\n","                polygons = [r['shape_attributes'] for r in a['regions']] \n","\n","            # load_mask() needs the image size to convert polygons to masks.\n","            # Unfortunately, VIA doesn't include it in JSON, so we must read\n","            # the image. This is only managable since the dataset is tiny.\n","            image_path = os.path.join(dataset_dir, a['filename'])\n","            image = skimage.io.imread(image_path)\n","            height, width = image.shape[:2]\n","\n","            self.add_image(\n","                \"balloon\",\n","                image_id=a['filename'],  # use file name as a unique image id\n","                path=image_path,\n","                width=width, height=height,\n","                polygons=polygons)\n","\n","    def load_mask(self, image_id):\n","        \"\"\"Generate instance masks for an image.\n","       Returns:\n","        masks: A bool array of shape [height, width, instance count] with\n","            one mask per instance.\n","        class_ids: a 1D array of class IDs of the instance masks.\n","        \"\"\"\n","        # If not a balloon dataset image, delegate to parent class.\n","        image_info = self.image_info[image_id]\n","        if image_info[\"source\"] != \"balloon\":\n","            return super(self.__class__, self).load_mask(image_id)\n","\n","        # Convert polygons to a bitmap mask of shape\n","        # [height, width, instance_count]\n","        info = self.image_info[image_id]\n","        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n","                        dtype=np.uint8)\n","        for i, p in enumerate(info[\"polygons\"]):\n","            # Get indexes of pixels inside the polygon and set them to 1\n","            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n","            mask[rr, cc, i] = 1\n","\n","        # Return mask, and array of class IDs of each instance. Since we have\n","        # one class ID only, we return an array of 1s\n","        return mask.astype(np.bool), np.ones([mask.shape[-1]], dtype=np.int32)\n","    \n","    '''def image_reference(self, image_id):\n","        \"\"\"Return the path of the image.\"\"\"\n","        info = self.image_info[image_id]\n","        if info[\"source\"] == \"balloon\":\n","            return info[\"path\"]\n","        else:\n","            super(self.__class__, self).image_reference(image_id)\n","    '''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AxHcVRPaGA9S","colab_type":"code","colab":{}},"source":["annotations = json.load(open(os.path.join(BALLOON_DATA_DIR, \"train/via_region_data.json\")))\n","annotations"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KDVbq1vrGA9Z","colab_type":"code","colab":{}},"source":["annotations = list(annotations.values())\n","annotations"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ziGkkf48GA9g","colab_type":"text"},"source":["### balloon 데이터 세트의 학습 수행. "]},{"cell_type":"markdown","metadata":{"id":"asHmKc0ZGA9h","colab_type":"text"},"source":["#### 학습과 Validation용 Dataset 설정."]},{"cell_type":"code","metadata":{"id":"vjCSRCnKGA9i","colab_type":"code","colab":{}},"source":["import skimage\n","\n","# Training dataset.\n","dataset_train = BalloonDataset()\n","dataset_train.load_balloon(BALLOON_DATA_DIR, \"train\")\n","dataset_train.prepare()\n","\n","# Validation dataset\n","dataset_val = BalloonDataset()\n","dataset_val.load_balloon(BALLOON_DATA_DIR, \"val\")\n","dataset_val.prepare()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SQ_rOYnrGA9s","colab_type":"text"},"source":["#### Config 설정"]},{"cell_type":"code","metadata":{"id":"WwGHwc8DGA9u","colab_type":"code","colab":{}},"source":["from mrcnn.config import Config\n","\n","TRAIN_IMAGE_CNT = len(dataset_train.image_info)\n","VALID_IMAGE_CNT = len(dataset_val.image_info)\n","\n","class BalloonConfig(Config):\n","    \"\"\"Configuration for training on the toy  dataset.\n","    Derives from the base Config class and overrides some values.\n","    \"\"\"\n","    # Give the configuration a recognizable name\n","    NAME = \"balloon\"\n","\n","    # Number of classes (including background)\n","    NUM_CLASSES = 1 + 1  # Background + balloon\n","\n","    # Skip detections with < 90% confidence\n","    DETECTION_MIN_CONFIDENCE = 0.9\n","    \n","    # We use a GPU with 12GB memory, which can fit two images.\n","    # Adjust down if you use a smaller GPU.\n","    IMAGES_PER_GPU = 1\n","    \n","    # 추가.\n","    GPU_COUNT = 1\n","\n","    # 원본에서 수정.\n","    #STEPS_PER_EPOCH = TRAIN_IMAGE_CNT  // IMAGES_PER_GPU\n","    #VALIDATION_STEPS = VALID_IMAGE_CNT  // IMAGES_PER_GPU\n","    \n","    # 원본 STEPS_PER_EPOCH\n","    STEPS_PER_EPOCH = TRAIN_IMAGE_CNT  // IMAGES_PER_GPU\n","    VALIDATION_STEPS = VALID_IMAGE_CNT  // IMAGES_PER_GPU\n","\n","    #BACKBONE = 'resnet101'\n","    \n","# config 설정. \n","train_config = BalloonConfig()\n","train_config.display()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fU2c46KAGA93","colab_type":"text"},"source":["#### 기반 Mask RCNN Training 모델 생성 및 초기 weight값 로딩\n","#### Matterport로 pretrained된 coco weight 모델을 다운로드함(최초시)\n","* 코랩 버전은 아래 코드로 pretrained 디렉토리를 재 생성해야함."]},{"cell_type":"code","metadata":{"id":"HIFF1lMe1rv0","colab_type":"code","colab":{}},"source":["!rm -rf /content/DLCV/Segmentation/mask_rcnn/pretrained\n","!mkdir /content/DLCV/Segmentation/mask_rcnn/pretrained"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hlve9e-x2WWK","colab_type":"code","colab":{}},"source":["from mrcnn import utils\n","\n","# 코랩 버전 수정\n","#ROOT_DIR = os.path.abspath('.')\n","ROOT_DIR = '/content/DLCV/Segmentation/mask_rcnn'\n","# 최초에는 coco pretrained 모델을 다운로드함. \n","COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"pretrained/mask_rcnn_coco.h5\")\n","\n","if not os.path.exists(COCO_MODEL_PATH):\n","    utils.download_trained_weights(COCO_MODEL_PATH)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kV-OJgsj2cmU","colab_type":"code","colab":{}},"source":["!ls /content/DLCV/Segmentation/mask_rcnn/pretrained"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4DP9VwQKGA95","colab_type":"code","colab":{}},"source":["import mrcnn.model as modellib\n","from mrcnn.model import log\n","\n","balloon_model = modellib.MaskRCNN(mode=\"training\", config=train_config, model_dir='./snapshots')\n","\n","# COCO 데이터 세트로 pretrained 된 모델을 이용하여 초기 weight값 로딩. \n","COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"pretrained/mask_rcnn_coco.h5\")\n","balloon_model.load_weights(COCO_MODEL_PATH, by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\"mrcnn_bbox\", \"mrcnn_mask\"])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GK1QBdE_GA9_","colab_type":"text"},"source":["#### 학습 수행"]},{"cell_type":"code","metadata":{"id":"C3Qmema7GA-B","colab_type":"code","colab":{}},"source":["'''\n","데이터 세트가 작고,단 하나의 클래스임. \n","pretrained 된 Coco 데이터 세트로 초기 weight 설정되었기에 RPN과 classifier만 학습해도 모델 성능은 큰 영향이 없을 거라 예상\n","all: All the layers\n","3+: Train Resnet stage 3 and up\n","4+: Train Resnet stage 4 and up\n","5+: Train Resnet stage 5 and up\n","'''\n","\n","print(\"Training network heads\")\n","balloon_model.train(dataset_train, dataset_val,\n","            learning_rate=train_config.LEARNING_RATE,\n","            epochs=30,\n","            layers='heads')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TUjNGsjYGA-I","colab_type":"text"},"source":["### 학습이 완료된 모델을 이용하여 inference 수행. \n","#### config를 inference용으로 변경"]},{"cell_type":"code","metadata":{"id":"R0VHA14kGA-J","colab_type":"code","colab":{}},"source":["class InferenceConfig(BalloonConfig):\n","    # NAME은 학습모델과 동일한 명을 부여\n","    NAME='balloon'\n","    GPU_COUNT = 1\n","    IMAGES_PER_GPU = 1\n","        \n","infer_config = InferenceConfig()\n","infer_config.display()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UtcG-VqBGA-P","colab_type":"text"},"source":["#### 학습된 모델의 weight 파일을 MaskRCNN의 inference 모델로 로딩. "]},{"cell_type":"code","metadata":{"id":"EoLH6UOgGA-Q","colab_type":"code","colab":{}},"source":["model = modellib.MaskRCNN(mode=\"inference\", model_dir='./snapshots', config=infer_config)\n","# callback에 의해 model weights 가 파일로 생성되며, 가장 마지막에 생성된 weights 가 가장 적은 loss를 가지는 것으로 가정. \n","weights_path = model.find_last()\n","print('model path:', weights_path)\n","# 지정된 weight 파일명으로 모델에 로딩. \n","model.load_weights(weights_path, by_name=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s8Xy7ojDGA-V","colab_type":"text"},"source":["#### Instance Segmentation을 수행할 파일들을 dataset로 로딩. val 디렉토리에 있는 파일들을 로딩. "]},{"cell_type":"code","metadata":{"id":"Djd07CuBGA-W","colab_type":"code","colab":{}},"source":["# Inference를 위해 val Dataset 재로딩. \n","dataset_val = BalloonDataset()\n","dataset_val.load_balloon(BALLOON_DATA_DIR, \"val\")\n","dataset_val.prepare()\n","\n","print(\"Images: {}\\nClasses: {}\".format(len(dataset_val.image_ids), dataset_val.class_names))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OaPMKOp_GA-c","colab_type":"code","colab":{}},"source":["from mrcnn import model as modellib\n","\n","# dataset중에 임의의 파일을 한개 선택. \n","#image_id = np.random.choice(dataset.image_ids)\n","image_id = 5\n","image, image_meta, gt_class_id, gt_bbox, gt_mask=modellib.load_image_gt(dataset_val, infer_config, image_id, use_mini_mask=False)\n","info = dataset_val.image_info[image_id]\n","print(\"image ID: {}.{} ({}) {}\".format(info[\"source\"], info[\"id\"], image_id, \n","                                       dataset_val.image_reference(image_id)))\n","\n","# Run object detection\n","results = model.detect([image], verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mzjBTg3rGA-f","colab_type":"code","colab":{}},"source":["r = results[0]\n","visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n","                            dataset_val.class_names, r['scores'], \n","                            title=\"Predictions\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VgrmK5SdGA-j","colab_type":"code","colab":{}},"source":["#Mask_RCNN 패키지의 samples/balloon 디렉토리의 balloon.py 를 import 한다. \n","# 코렙 버전 디렉토리 수정. \n","#ROOT_DIR = os.path.abspath(\".\")\n","ROOT_DIR = '/content/DLCV/Segmentation/mask_rcnn'\n","sys.path.append(os.path.join(ROOT_DIR, \"Mask_RCNN/samples/balloon/\"))\n","\n","import balloon\n","from mrcnn.visualize import display_images\n","\n","splash = balloon.color_splash(image, r['masks'])\n","display_images([splash], cols=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PikdTiTQGA-o","colab_type":"code","colab":{}},"source":["def color_splash(image, mask):\n","    \"\"\"Apply color splash effect.\n","    image: RGB image [height, width, 3]\n","    mask: instance segmentation mask [height, width, instance count]\n","    Returns result image.\n","    \"\"\"\n","    # Make a grayscale copy of the image. The grayscale copy still\n","    # has 3 RGB channels, though.\n","    gray = skimage.color.gray2rgb(skimage.color.rgb2gray(image)) * 255\n","    # Copy color pixels from the original color image where mask is set\n","    if mask.shape[-1] > 0:\n","        # We're treating all instances as one, so collapse the mask into one layer\n","        mask = (np.sum(mask, -1, keepdims=True) >= 1)\n","        splash = np.where(mask, image, gray).astype(np.uint8)\n","    else:\n","        splash = gray.astype(np.uint8)\n","    return splash"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vDNmu2d5GA-t","colab_type":"text"},"source":["#### 각 변수 shape debug"]},{"cell_type":"code","metadata":{"id":"UmJ1yeEbGA-u","colab_type":"code","colab":{}},"source":["print('image shape:',image.shape, 'r mask shape:',r['masks'].shape)\n","mask = (np.sum(r['masks'], -1, keepdims=True) >= 1)\n","print('sum mask shape:',mask.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FS0blqjjGA-y","colab_type":"text"},"source":["#### np.sum() 테스트"]},{"cell_type":"code","metadata":{"id":"fCQtR8ziGA-z","colab_type":"code","colab":{}},"source":["a = np.ones((10, 10, 3))\n","#print(a)\n","#print(np.sum(a))\n","print(np.sum(a, axis=-1).shape)\n","print(np.sum(a, -1, keepdims=True).shape)\n","print(np.sum(a, -1, keepdims=True) >=1 )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z5hwdeXOGA-3","colab_type":"text"},"source":["#### np.where() 테스트"]},{"cell_type":"code","metadata":{"id":"To4ONjtjGA-6","colab_type":"code","colab":{}},"source":["test_mask = (np.sum(a, -1, keepdims=True) >=1)\n","print(test_mask.shape)\n","for i in range(5):\n","    for j in range(5):\n","        test_mask[i, j, 0] = False\n","        \n","test_image = np.ones((10, 10, 3))\n","test_gray = np.zeros((10, 10, 3))\n","np.where(test_mask, test_image, test_gray)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4QRYNPfbGA-9","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PxcnQujKGA_A","colab_type":"text"},"source":["#### Video에 color splash를 적용. "]},{"cell_type":"code","metadata":{"id":"1EvLp9vdmETW","colab_type":"code","colab":{}},"source":["# 코랩 버전은 아래 코드를 이용합니다.\n","from IPython.display import HTML\n","from base64 import b64encode\n","mp4 = open('/content/DLCV/data/video/balloon_dog02.mp4','rb').read()\n","data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","HTML(\"\"\"\n","<video width=800 controls>\n","      <source src=\"%s\" type=\"video/mp4\">\n","</video>\n","\"\"\" % data_url)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pgw2o744GA_E","colab_type":"text"},"source":["#### Video color splash를 적용한 함수를 생성하고 이를 이용해 video color splash 수행. "]},{"cell_type":"code","metadata":{"id":"31-i9aY7GA_F","colab_type":"code","colab":{}},"source":["import cv2\n","import time\n","\n","def detect_video_color_splash(model, video_input_path=None, video_output_path=None):\n","\n","    cap = cv2.VideoCapture(video_input_path)\n","    codec = cv2.VideoWriter_fourcc(*'XVID')\n","    fps = round(cap.get(cv2.CAP_PROP_FPS))\n","    vid_writer = cv2.VideoWriter(video_output_path, codec, fps, (round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n","                                                                 round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n","\n","    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    print(\"총 Frame 개수: {0:}\".format(total))\n","\n","    frame_index = 0\n","    success = True\n","    while True:\n","        \n","        hasFrame, image_frame = cap.read()\n","        if not hasFrame:\n","            print('End of frame')\n","            break\n","        frame_index += 1\n","        print(\"frame index:{0:}\".format(frame_index), end=\" \")\n","        \n","        # OpenCV returns images as BGR, convert to RGB\n","        image_frame = image_frame[..., ::-1]\n","        start=time.time()\n","        # Detect objects\n","        r = model.detect([image_frame], verbose=0)[0]\n","        print('detected time:', time.time()-start)\n","        # Color splash\n","        splash = color_splash(image_frame, r['masks'])\n","        # RGB -> BGR to save image to video\n","        splash = splash[..., ::-1]\n","        # Add image to video writer\n","        vid_writer.write(splash)\n","    \n","    vid_writer.release()\n","    cap.release()       \n","    \n","    print(\"Saved to \", video_output_path)\n","    \n","detect_video_color_splash(model, video_input_path='/content/DLCV/data/video/balloon_dog02.mp4', \n","                          video_output_path='/content/DLCV/data/output/balloon_dog02_output.avi')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"06Ns_jzSGA_I","colab_type":"text"},"source":["#### 생성된 Output 파일을 Google drive 에 저장한 뒤 확인"]},{"cell_type":"code","metadata":{"id":"kf1K-zP5m5D4","colab_type":"code","colab":{}},"source":["## colab 버전은 Object Detection 적용된 영상 파일을 google drive에서 download 해야 합니다. 이를 위해 google drive를 colab에 mount 수행. \n","import os, sys \n","from google.colab import drive \n","\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XNQA71YKGA_S","colab_type":"code","colab":{}},"source":["## colab 버전은 Object Detection 적용된 영상 파일을 google drive에서 download 해야 합니다. \n","## My Drive 디렉토리 이름에 공란이 있으므로 ' '로 묶습니다. \n","!cp /content/DLCV/data/output/balloon_dog02_output.avi '/content/gdrive/My Drive/balloon_dog02_output.avi'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iaMG6tc6oS2y","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}