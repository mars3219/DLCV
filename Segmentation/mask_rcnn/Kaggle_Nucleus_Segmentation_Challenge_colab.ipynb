{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python [conda env:tf113] *","language":"python","name":"conda-env-tf113-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"},"colab":{"name":"Kaggle_Nucleus_Segmentation_Challenge_colab.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"PP660ID4pp5F","colab_type":"text"},"source":["### Kaggle Nucleus Segmentation Challenge"]},{"cell_type":"markdown","metadata":{"id":"Y8RvXJVjpkKq","colab_type":"text"},"source":["### 본 실습 예제는 GPU를 활용하므로 상단 메뉴에서 런타임->런타임 유형 변경에서 GPU를 선택해 주십시요. \n","\n","tensorflow, keras 설치 및 강의 실습코드/데이터 Download\n","\n","**공지**\n","\n","현재(2020년 8월 11일) Colab에서 GPU 커널 적용시 tensorflow 1.13으로 downgrade가 되지 않습니다. \n","때문에 colab에서는 Segmentation 학습 시 tensorflow 1.15, keras 2.3 을 설치하겠습니다. \n","\n","Colab 버전colab에서 pip 명령어를 이용하여 tensorflow 1.15, keras 2.3를 소스코드 커널 기동시 마다 설치해야 합니다\n","\n","Colab의 tensorflow는 2020년 기준으로 2.2 이며, keras는 2.3입니다. 실습코드는 tensorflow 1.13과 1.15, keras 2.2와 2.3 기준으로 되어 있으므로 이를 downgrade해야 합니다.\n","\n","pip를 이용하여 tensorflow 1.15을 설치하면 자동으로 downgrade 됩니다.\n","\n","OpenCV는 Colab에서 이미 설치 되어 있으니 추가설치는 필요 없습니다.\n","\n","강의 실습코드와 데이터는 https://github.com/chulminkw/DLCV.git 에서 다운로드 할 수 있습니다. "]},{"cell_type":"code","metadata":{"id":"Nxndp5hFps99","colab_type":"code","colab":{}},"source":["# 현재 디렉토리는 /content이며 이 디렉토리를 기준으로 실습코드와 데이터를 다운로드 합니다. \n","!pwd\n","!git clone https://github.com/chulminkw/DLCV.git\n","# DLCV 디렉토리가 Download되고 DLCV 밑에 Detection과 Segmentation 디렉토리가 있는 것을 확인\n","!ls -lia \n","!ls -lia DLCV\n","\n","# tensorflow 1.15을 설치합니다. 자동으로 tensorflow 2.2가 1.15로 downgrade 됩니다. \n","!pip install tensorflow-gpu==1.15.2 \n","# keras 2.3를 설치합니다. \n","!pip install keras==2.3.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DPeZJxsMpwmg","colab_type":"code","colab":{}},"source":["# tensorflow는 1.15, keras는 2.3 버전 확인\n","# GPU가 세팅되어 있지 않으면 상단 메뉴에서 런타임->런타임 유형 변경에서 GPU를 선택한 후 런타임 다시 시작을 선택하고 처음 부터인 tensorflow, keras 설치 부터 다시 시작. \n","import tensorflow as tf\n","import keras\n","\n","print(tf.__version__)\n","print(keras.__version__)\n","\n","# gpu가 세팅되어 있는지 확인. \n","tf.test.gpu_device_name()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wgzib3Z2p27M","colab_type":"text"},"source":["#### Matterport Mask RCNN 패키지 다운로드 \n","\n","#### 중요\n","Mask_RCNN은 현재 (2020년 8월 11일 기준) tensorflow 1.15 적용시 소스 코드의 변경이 필요합니다.\n","\n","아래에서 Mask_RCNN.git 설치 후 기존 mrcnn/model.py를 삭제하고 아래와 같이 새로운 소스코드를 https://raw.githubusercontent.com/rteuwens/Mask_RCNN/master/mrcnn/model.py 에서 다운로드 받은 후에 설치 필요. "]},{"cell_type":"code","metadata":{"id":"navifmmNpzMs","colab_type":"code","colab":{}},"source":["# Mask_RCNN 다운로드 \n","%cd /content/DLCV/Segmentation/mask_rcnn\n","!git clone https://github.com/matterport/Mask_RCNN.git\n","\n","# 중요.아래에서 Mask_RCNN.git 설치 후 기존 mrcnn/model.py를 삭제하고 \n","# 아래와 같이 새로운 소스코드를 https://raw.githubusercontent.com/rteuwens/Mask_RCNN/master/mrcnn/model.py 에서 다운로드 받은 후에 설치 필요.  \n","%cd /content/DLCV/Segmentation/mask_rcnn/Mask_RCNN/mrcnn\n","!rm model.py\n","!wget https://raw.githubusercontent.com/rteuwens/Mask_RCNN/master/mrcnn/model.py"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Inq_3sAYTuHk","colab_type":"text"},"source":["#### Mask_RCNN 패키지 설치"]},{"cell_type":"code","metadata":{"id":"RNhMZG5eTo4Y","colab_type":"code","colab":{}},"source":["# 다운로드한 Mask_RCNN 디렉토리로 이동하여 Mask_RCNN 패키지 설치. \n","%cd /content/DLCV/Segmentation/mask_rcnn/Mask_RCNN\n","#!pip install -r requirements.txt\n","!python setup.py install"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ofRWM7hCokja","colab_type":"code","colab":{}},"source":["import os\n","import sys\n","import random\n","import math\n","import re\n","import time\n","import numpy as np\n","import tensorflow as tf\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","%matplotlib inline "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SH3oKFmcokjp","colab_type":"code","colab":{}},"source":["from mrcnn.config import Config\n","from mrcnn import utils\n","from mrcnn import visualize\n","from mrcnn.visualize import display_images\n","import mrcnn.model as modellib\n","from mrcnn.model import log"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aMqbmc_Iokj5","colab_type":"code","colab":{}},"source":["## Kaggle에서 2018 Data science bowl Nucleus segmentation 데이터를 download 한 뒤 ./nucleus_data 디렉토리에 압축을 품\n","# stage1_train.zip 파일에 train용 image 데이터와 mask 데이터가 있음. stage1_train_zip 파일을 stage1_train 디렉토리에 압축 해제\n","# unzip stage1_train.zip -d stage1_train\n","# stage1_test.zip 파일에 test용 image 데이터와 mask 데이터가 있음. stage1_test_zip 파일을 stage1_test 디렉토리에 압축 해제\n","# unzip stage1_test.zip -d stage1_test"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u3kwovbhokkB","colab_type":"text"},"source":["**train용 데이터 세트에 들어있는 데이터 구조 확인**"]},{"cell_type":"code","metadata":{"id":"1itOxr-tvjip","colab_type":"code","colab":{}},"source":["!pwd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p_oqvN-UuzKn","colab_type":"code","colab":{}},"source":["# nucleus 데이터 세트 디렉토리 생성. \n","!rm -rf /content/DLCV/data/nucleus\n","!mkdir /content/DLCV/data/nucleus\n","!mkdir /content/DLCV/data/nucleus/stage1_train\n","# nucleus 데이터 세트 download 후 zip 압축 해제\n","%cd /content/DLCV/data/nucleus/stage1_train\n","!wget https://github.com/chulminkw/DLCV/releases/download/1.0/stage1_train.zip\n","!echo \"#### unzip stage1_train.zip\"\n","!unzip stage1_train.zip > /dev/null 2>&1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7818xgaXw-iq","colab_type":"code","colab":{}},"source":["!ls /content/DLCV/data/nucleus/stage1_train"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WXfywbY-okkC","colab_type":"code","colab":{}},"source":["import os\n","from pathlib import Path\n","# 코렙 버전 디렉토리 수정. \n","#HOME_DIR = str(Path.home())\n","HOME_DIR = '/content'\n","# 학습용, 테스트용 모두의 기준 디렉토리는 ~/DLCV/data/nucleus 임. \n","DATASET_DIR = os.path.join(HOME_DIR, \"DLCV/data/nucleus\")\n","print(DATASET_DIR)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WkfTObGEokkJ","colab_type":"code","colab":{}},"source":["# ~/DLCV/data/nucleus 디렉토리 밑에 학습용 디렉토리인 stage1_train이 만들어짐.stage1_train에 학습 이미지, mask 이미지 데이터 존재. \n","subset_dir = 'stage1_train'\n","train_dataset_dir = os.path.join(DATASET_DIR, subset_dir)\n","print(train_dataset_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CctQ-qmLokkQ","colab_type":"code","colab":{}},"source":["# train 데이터 세트의 이미지 파일, mask 파일이 어떠한 디렉토리 구조 형태로 저장되어 있는지 확인. "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"woqy23BjokkX","colab_type":"code","colab":{}},"source":["# 이미지 별로 고유한 이미지명을 가지는 이미지 디렉토리를 가지고 이 디렉토리에 하위 디렉토리로 images, masks를 가짐\n","# images 에는 하나의 이미지가 있으며 masks는 여러개의 mask 이미지 파일을 가지고 있음. 즉 하나의 이미지에 여러개의 mask 파일을 가지고 있는 형태임. \n","# next(os.walk(directory))[1]은 sub directory를 iteration으로 반환 next(os.walk(directory))[2]는 해당 디렉토리 밑에 파일들을 iteration으로 반환\n","index = 0 \n","for dir in next(os.walk(train_dataset_dir))[1]:\n","    print('',dir)\n","    subdirs = os.path.join(train_dataset_dir, dir)\n","    for subdir in next(os.walk(subdirs))[1]:\n","        print('----'+subdir)\n","        sub_subdirs = os.path.join(subdirs, subdir)\n","        for sub_subdir in next(os.walk(sub_subdirs))[2]:\n","            print('    ---- '+sub_subdir)\n","            index += 1\n","            if index >1000:\n","                break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mOEI9-Ipokkd","colab_type":"code","colab":{}},"source":["### 학습시 사용할 임의의 Validation용 IMAGE ID를 별도로 선정. "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HPJi47gYokki","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","np.random.seed(0)\n","def get_valid_image_ids(dataset_dir, valid_size):\n","    \n","    dataset_dir = os.path.join(dataset_dir,'stage1_train')\n","    image_ids = next(os.walk(dataset_dir))[1]\n","    total_cnt = len(image_ids)\n","    \n","    valid_cnt = int(total_cnt * valid_size)\n","    valid_indexes = np.random.choice(total_cnt, valid_cnt, replace=False)\n","    \n","    return list(np.array(image_ids)[valid_indexes])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jsyHioEAokkp","colab_type":"code","colab":{}},"source":["get_valid_image_ids(DATASET_DIR, 0.1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nTOMnUUBokku","colab_type":"code","colab":{}},"source":["## Dataset객체의 add_image()를 이용하여 개별 이미지를 Dataset 객체로 로딩하는 load_nucleus() 함수 생성. "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pFLQeHT0okk2","colab_type":"code","colab":{}},"source":["from mrcnn import utils\n","import skimage\n","import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","VAL_IMAGE_IDS = get_valid_image_ids(DATASET_DIR, 0.1)\n","\n","class NucleusDataset(utils.Dataset):\n","    \n","    # subset은 train, valid, stage1_test, stage2_test\n","    def load_nucleus(self, dataset_dir, subset):\n","        self.add_class(source='nucleus', class_id=1, class_name='nucleus')\n","        \n","        subset_dir = 'stage1_train' if subset in ['train', 'val'] else subset\n","        dataset_dir = os.path.join(dataset_dir, subset_dir)\n","        \n","        if subset=='val':\n","            image_ids = VAL_IMAGE_IDS\n","        else:\n","            image_ids = next(os.walk(dataset_dir))[1]\n","            if subset=='train':\n","                image_ids = list(set(image_ids) - set(VAL_IMAGE_IDS))\n","\n","        for image_id in image_ids:       \n","            self.add_image('nucleus', image_id=image_id, path=os.path.join(dataset_dir, image_id, 'images/{}.png'.format(image_id)))\n","    \n","    def load_mask(self, image_id):\n","        info = self.image_info[image_id]\n","        mask_dir = os.path.join(os.path.dirname(os.path.dirname(info['path'])), 'masks')\n","        mask_list=[]\n","        for mask_file in next(os.walk(mask_dir))[2]:\n","            if mask_file.endswith('.png'):\n","                mask = skimage.io.imread(os.path.join(mask_dir, mask_file)).astype(np.bool)\n","                mask_list.append(mask)\n","                \n","        masks = np.stack(mask_list, axis=-1)\n","        \n","        return masks, np.ones([masks.shape[-1]], dtype=np.int32)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2d3q_a0Xokk8","colab_type":"code","colab":{}},"source":["nucleus_dataset = NucleusDataset(utils.Dataset)\n","nucleus_dataset.load_nucleus(DATASET_DIR, 'train')\n","#print('class info:', nucleus_dataset.class_info)\n","#print('image info:', nucleus_dataset.image_info)\n","nucleus_dataset.prepare()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hYLQYYuPoklC","colab_type":"code","colab":{}},"source":["print('class id:', nucleus_dataset.class_ids)\n","print('image id:', nucleus_dataset._image_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c8yoMQ2xoklJ","colab_type":"code","colab":{}},"source":["nucleus_dataset.image_info[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yRnr_n8OoklO","colab_type":"code","colab":{}},"source":["masks, class_ids = nucleus_dataset.load_mask(0)\n","masks.shape, class_ids.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"neGR_CjboklT","colab_type":"code","colab":{}},"source":["masks, class_ids = nucleus_dataset.load_mask(0)\n","\n","sample_img = skimage.io.imread(os.path.join(DATASET_DIR, 'stage1_train', \n","                        'df53d0b6c2c4e45d759b2c474011e2b2b32552cd100ca4b22388ab9ca1750ee2',\n","                        'images',\n","                        'df53d0b6c2c4e45d759b2c474011e2b2b32552cd100ca4b22388ab9ca1750ee2.png'))\n","print('image shape:', sample_img.shape)\n","plt.imshow(sample_img)\n","plt.show()\n","\n","print(masks[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SKPlwn33oklX","colab_type":"code","colab":{}},"source":["np.random.seed(0)\n","image_ids = np.random.choice(nucleus_dataset.image_ids, 4)\n","print(image_ids)\n","for image_id in image_ids:\n","    image = nucleus_dataset.load_image(image_id)\n","    mask, class_ids = nucleus_dataset.load_mask(image_id)\n","    print('mask shape:', mask.shape, 'class_ids shape:', class_ids.shape)\n","    visualize.display_top_masks(image, mask, class_ids, nucleus_dataset.class_names, limit=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UXNXWpj8oklb","colab_type":"text"},"source":["### nucleus 데이터 세트 Train/Inference \n","* Matterport 패키지에서 사용될 수 있도록 학습/검증/테스트 데이터 세트를 변환하여 생성 필요\n","* 학습 또는 Inference를 위한 Config 설정.  "]},{"cell_type":"code","metadata":{"id":"tCCQLktboklc","colab_type":"code","colab":{}},"source":["dataset_train = NucleusDataset()\n","dataset_train.load_nucleus(DATASET_DIR, 'train')\n","# dataset을 load한 뒤에는 반드시 prepare()메소드를 호출\n","dataset_train.prepare()\n","\n","# Validation dataset\n","dataset_val = NucleusDataset()\n","dataset_val.load_nucleus(DATASET_DIR, \"val\")\n","dataset_val.prepare()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B0WMAAW_oklh","colab_type":"code","colab":{}},"source":["len(dataset_train.image_info), len(dataset_val.image_info)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lXzs_kKNokll","colab_type":"text"},"source":["#### Nucleus 학습을 위한 새로운 Config 생성"]},{"cell_type":"code","metadata":{"id":"H9C1YHqxoklo","colab_type":"code","colab":{}},"source":["from mrcnn.config import Config\n","\n","train_image_cnt = len(dataset_train.image_info)\n","val_image_cnt = len(dataset_val.image_info)\n","print('train_image_cnt:',train_image_cnt, 'validation image count:',val_image_cnt)\n","\n","class NucleusConfig(Config):\n","    \"\"\"Configuration for training on the nucleus segmentation dataset.\"\"\"\n","    # Give the configuration a recognizable name\n","    NAME = \"nucleus\"\n","\n","    # Adjust depending on your GPU memory\n","    IMAGES_PER_GPU = 6\n","\n","    # Number of classes (including background)\n","    NUM_CLASSES = 1 + 1  # Background + nucleus\n","\n","    # Number of training and validation steps per epoch\n","    STEPS_PER_EPOCH = (train_image_cnt) // IMAGES_PER_GPU\n","    VALIDATION_STEPS = max(1, (val_image_cnt // IMAGES_PER_GPU))\n","\n","    # Don't exclude based on confidence. Since we have two classes\n","    # then 0.5 is the minimum anyway as it picks between nucleus and BG\n","    DETECTION_MIN_CONFIDENCE = 0\n","\n","    # Backbone network architecture\n","    # Supported values are: resnet50, resnet101\n","    BACKBONE = \"resnet50\"\n","\n","    # Input image resizing\n","    # Random crops of size 512x512\n","    IMAGE_RESIZE_MODE = \"crop\"\n","    IMAGE_MIN_DIM = 512\n","    IMAGE_MAX_DIM = 512\n","    IMAGE_MIN_SCALE = 2.0\n","\n","    # Length of square anchor side in pixels\n","    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)\n","\n","    # ROIs kept after non-maximum supression (training and inference)\n","    POST_NMS_ROIS_TRAINING = 1000\n","    POST_NMS_ROIS_INFERENCE = 2000\n","\n","    # Non-max suppression threshold to filter RPN proposals.\n","    # You can increase this during training to generate more propsals.\n","    RPN_NMS_THRESHOLD = 0.9\n","\n","    # How many anchors per image to use for RPN training\n","    RPN_TRAIN_ANCHORS_PER_IMAGE = 64\n","\n","    # Image mean (RGB)\n","    MEAN_PIXEL = np.array([43.53, 39.56, 48.22])\n","\n","    # If enabled, resizes instance masks to a smaller size to reduce\n","    # memory load. Recommended when using high-resolution images.\n","    USE_MINI_MASK = True\n","    MINI_MASK_SHAPE = (56, 56)  # (height, width) of the mini-mask\n","\n","    # Number of ROIs per image to feed to classifier/mask heads\n","    # The Mask RCNN paper uses 512 but often the RPN doesn't generate\n","    # enough positive proposals to fill this and keep a positive:negative\n","    # ratio of 1:3. You can increase the number of proposals by adjusting\n","    # the RPN NMS threshold.\n","    TRAIN_ROIS_PER_IMAGE = 128\n","\n","    # Maximum number of ground truth instances to use in one image\n","    MAX_GT_INSTANCES = 200\n","\n","    # Max number of final detections per image\n","    DETECTION_MAX_INSTANCES = 400"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3SSeaz4-y-7_","colab_type":"text"},"source":["#### 기반 Mask RCNN Training 모델 생성 및 초기 weight값 로딩\n","#### Matterport로 pretrained된 coco weight 모델을 다운로드함(최초시)\n","* 코랩 버전은 아래 코드로 pretrained 디렉토리를 재 생성해야함."]},{"cell_type":"code","metadata":{"id":"41D7kARfy54P","colab_type":"code","colab":{}},"source":["!rm -rf /content/DLCV/Segmentation/mask_rcnn/pretrained\n","!mkdir /content/DLCV/Segmentation/mask_rcnn/pretrained"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yEuHyWZczD2B","colab_type":"code","colab":{}},"source":["from mrcnn import utils\n","\n","# 코랩 버전 수정\n","#ROOT_DIR = os.path.abspath('.')\n","ROOT_DIR = '/content/DLCV/Segmentation/mask_rcnn'\n","# 최초에는 coco pretrained 모델을 다운로드함. \n","COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"pretrained/mask_rcnn_coco.h5\")\n","\n","if not os.path.exists(COCO_MODEL_PATH):\n","    utils.download_trained_weights(COCO_MODEL_PATH)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mn5Kdedaoklx","colab_type":"text"},"source":["#### coco  pretrained된 가중치 모델 위치 지정. "]},{"cell_type":"code","metadata":{"id":"T6-Qa2bZoklz","colab_type":"code","colab":{}},"source":["# 코렙 버전 디렉토리 수정. \n","#ROOT_DIR = os.path.abspath(\"./\")\n","ROOT_DIR = '/content/DLCV/Segmentation/mask_rcnn'\n","# Path to trained weights file\n","COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"pretrained/mask_rcnn_coco.h5\")\n","\n","# Directory to save logs and model checkpoints, if not provided\n","# through the command line argument --logs\n","MODEL_DIR = os.path.join(ROOT_DIR, \"snapshots/nucleus\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WJr23nU7okl4","colab_type":"text"},"source":["#### 학습을 위한 모델을 생성, Mask_RCNN 패키지는 modellib에 MaskRCNN 객체를 이용하여 Mask RCNN 모델을 생성함. \n","\n","생성 인자\n","* mode: training인지 inference인지 설정\n","* config: training 또는 inference에 따라 다른 config 객체 사용. Config객체를 상속 받아 각 경우에 새로운 객체를 만들고 이를 이용. \n","inference 시에는 Image를 하나씩 입력 받아야 하므로 Batch size를 1로 만들 수 있도록 설정 \n","            \n","* model_dir: 학습 진행 중에 Weight 모델이 저장되는 장소 지정.   "]},{"cell_type":"code","metadata":{"id":"tFnnXE-nokl7","colab_type":"code","colab":{}},"source":["from mrcnn import model as modellib\n","\n","train_config = NucleusConfig()\n","train_config.display()\n","\n","model = modellib.MaskRCNN(mode=\"training\", config=train_config,\n","                                  model_dir=MODEL_DIR)\n","\n","# Exclude the last layers because they require a matching\n","# number of classes\n","model.load_weights(COCO_WEIGHTS_PATH, by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\"mrcnn_bbox\", \"mrcnn_mask\"])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LUp31oUSokmC","colab_type":"text"},"source":["#### 학습 데이터 세트와 검증 데이터 세트를 NucleusDataset 객체에 로드하고 train 시작\n","* augmentation은 imgaug를 사용. "]},{"cell_type":"code","metadata":{"id":"cTXOnt9HokmC","colab_type":"code","colab":{}},"source":["#imgaug 패키지는 Default로 Colab에 설치되어 있음. \n","from imgaug import augmenters as iaa\n","\n","img_aug = iaa.SomeOf((0, 2), [\n","        iaa.Fliplr(0.5),\n","        iaa.Flipud(0.5),\n","        iaa.OneOf([iaa.Affine(rotate=90),\n","                   iaa.Affine(rotate=180),\n","                   iaa.Affine(rotate=270)]),\n","        iaa.Multiply((0.8, 1.5)),\n","        iaa.GaussianBlur(sigma=(0.0, 5.0))\n","    ])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"d1eXxqy3okmH","colab_type":"code","colab":{}},"source":["# 코렙에서 수행 시 약 8시간 정도의 시간이 필요합니다.료\n","# 여유가 된다면 끝까지, 그렇지 않으면 epoch를 15회 정도 수행후 강제로 학습을 종료. 이 경우 15회 epoch된 weight 파일을 기반으로 inference 모델 생성 가능 \n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","print(\"Train all layers\")\n","model.train(dataset_train, dataset_val,\n","            learning_rate=train_config.LEARNING_RATE,\n","            epochs=40, augmentation=img_aug,\n","            layers='all')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ER-4E_tookmP","colab_type":"text"},"source":["#### 학습 모델을 이용하여 Inference 수행"]},{"cell_type":"code","metadata":{"id":"-Ffnr_9RokmQ","colab_type":"code","colab":{}},"source":["## 예측용 모델을 로드. mode는 inference로 설정,config는 NucleusInferenceConfig()로 설정,\n","## 예측용 모델에 위에서 찾은 학습 중 마지막 저장된 weight파일을 로딩함. "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RSZJ7bwCokmV","colab_type":"code","colab":{}},"source":["class NucleusInferenceConfig(NucleusConfig):\n","    NAME='nucleus'\n","    # 이미지 한개씩 차례로 inference하므로 batch size를 1로 해야 하며 이를 위해 IMAGES_PER_GPU = 1\n","    GPU_COUNT = 1\n","    IMAGES_PER_GPU = 1\n","    # pad64는 64 scale로 이미지를 맞춰서 resize수행. \n","    IMAGE_RESIZE_MODE = \"pad64\"\n","    # Non-max suppression threshold to filter RPN proposals.\n","    # You can increase this during training to generate more propsals.\n","    RPN_NMS_THRESHOLD = 0.7\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0qd5BjnKokmb","colab_type":"code","colab":{}},"source":["infer_config = NucleusInferenceConfig()\n","inference_model = modellib.MaskRCNN(mode=\"inference\", config=infer_config, model_dir=MODEL_DIR)\n","weights_path = model.find_last()\n","print('학습중 마지막으로 저장된 weight 파일:', weights_path)\n","inference_model.load_weights(weights_path, by_name=True)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6ROpnT35n7ko","colab_type":"text"},"source":["#### 코랩 버전은 test 용 데이터 세트를 아래와 같이 생성. "]},{"cell_type":"code","metadata":{"id":"EQ82kxMRnpyu","colab_type":"code","colab":{}},"source":["# nucleus 데이터 세트 디렉토리 생성. \n","!mkdir /content/DLCV/data/nucleus/stage1_test\n","# nucleus 데이터 세트 download 후 zip 압축 해제\n","%cd /content/DLCV/data/nucleus/stage1_test\n","!wget https://github.com/chulminkw/DLCV/releases/download/1.0/stage1_test.zip\n","!echo \"#### unzip stage1_test.zip\"\n","!unzip stage1_test.zip > /dev/null 2>&1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qX7ivNa0okmg","colab_type":"code","colab":{}},"source":["### 테스트용 데이터 세트를 NucleusDataset으로 로딩. load_nucleus() 테스트 세트를 지정하는 'stage1_test'를 입력. \n","dataset_test = NucleusDataset()\n","dataset_test.load_nucleus(DATASET_DIR, 'stage1_test')\n","dataset_test.prepare()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u5EwCyn4okml","colab_type":"code","colab":{}},"source":["dataset_test.image_ids"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eMyJBBRFokms","colab_type":"code","colab":{}},"source":["### mask detected 된 임의의 파일을 시각화"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gmSRdmLAokmz","colab_type":"code","colab":{}},"source":["for image_id in dataset_test.image_ids:\n","        # Load image and run detection\n","        image = dataset_test.load_image(image_id)\n","        print(len(image))\n","        # Detect objects\n","        r = inference_model.detect([image], verbose=0)[0]\n","        # Save image with masks\n","        visualize.display_instances(\n","            image, r['rois'], r['masks'], r['class_ids'],\n","            dataset_test.class_names, r['scores'],\n","            show_bbox=False, show_mask=False,\n","            title=\"Predictions\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A_-IKLhSokm2","colab_type":"code","colab":{}},"source":["for image_id in dataset_test.image_ids:\n","        # Load image and run detection\n","        image = dataset_test.load_image(image_id)\n","        print(len(image))\n","       \n","        #plt.savefig(\"{}/{}.png\".format(submit_dir, dataset.image_info[image_id][\"id\"]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Rlvpdg3okm8","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k2ATB4v4oknE","colab_type":"code","colab":{}},"source":["detect(model, args.dataset, args.subset)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I_xSMli7oknM","colab_type":"code","colab":{}},"source":["def detect(model, dataset_dir, subset):\n","    \"\"\"Run detection on images in the given directory.\"\"\"\n","    print(\"Running on {}\".format(dataset_dir))\n","\n","    # Create directory\n","    if not os.path.exists(RESULTS_DIR):\n","        os.makedirs(RESULTS_DIR)\n","    submit_dir = \"submit_{:%Y%m%dT%H%M%S}\".format(datetime.datetime.now())\n","    submit_dir = os.path.join(RESULTS_DIR, submit_dir)\n","    os.makedirs(submit_dir)\n","\n","    # Read dataset\n","    dataset = NucleusDataset()\n","    dataset.load_nucleus(dataset_dir, subset)\n","    dataset.prepare()\n","    # Load over images\n","    submission = []\n","    for image_id in dataset.image_ids:\n","        # Load image and run detection\n","        image = dataset.load_image(image_id)\n","        # Detect objects\n","        r = model.detect([image], verbose=0)[0]\n","        # Encode image to RLE. Returns a string of multiple lines\n","        source_id = dataset.image_info[image_id][\"id\"]\n","        rle = mask_to_rle(source_id, r[\"masks\"], r[\"scores\"])\n","        submission.append(rle)\n","        # Save image with masks\n","        visualize.display_instances(\n","            image, r['rois'], r['masks'], r['class_ids'],\n","            dataset.class_names, r['scores'],\n","            show_bbox=False, show_mask=False,\n","            title=\"Predictions\")\n","        plt.savefig(\"{}/{}.png\".format(submit_dir, dataset.image_info[image_id][\"id\"]))\n","\n","    # Save to csv file\n","    submission = \"ImageId,EncodedPixels\\n\" + \"\\n\".join(submission)\n","    file_path = os.path.join(submit_dir, \"submit.csv\")\n","    with open(file_path, \"w\") as f:\n","        f.write(submission)\n","    print(\"Saved to \", submit_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OPk9SjdVoknQ","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bgjwc27roknX","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jGmju7IUoknd","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F4RIhHd_oknk","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zRE_VQRVoknn","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A7a5lpSqoknu","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}